{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series RandomSearch Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "* [Time Series Forecasting on Stock Prices](https://www.youtube.com/watch?v=j05UUs99eNQ) from [Coding Tech](https://www.youtube.com/channel/UCtxCXg-UvSnTKPOzLH4wJaQ)\n",
    "\n",
    "Related:\n",
    "* https://iknowfirst.com/stock-forecast-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** _Investing in the stock market involves risk and can lead to monetary loss. This material is purely for educational purposes and should not be taken as professional investment advice. Invest at your own discretion._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SP500.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>94.484962</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>775500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>92.169162</td>\n",
       "      <td>94.190231</td>\n",
       "      <td>1850600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>373900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-24</td>\n",
       "      <td>92.800753</td>\n",
       "      <td>94.358660</td>\n",
       "      <td>92.063905</td>\n",
       "      <td>94.148132</td>\n",
       "      <td>400300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-25</td>\n",
       "      <td>94.337613</td>\n",
       "      <td>94.948145</td>\n",
       "      <td>92.884970</td>\n",
       "      <td>93.284973</td>\n",
       "      <td>69600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5359</th>\n",
       "      <td>2021-09-08</td>\n",
       "      <td>452.899994</td>\n",
       "      <td>453.679993</td>\n",
       "      <td>450.869995</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>4076800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5360</th>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>452.690002</td>\n",
       "      <td>454.579987</td>\n",
       "      <td>450.730011</td>\n",
       "      <td>450.980011</td>\n",
       "      <td>3851600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5361</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>453.059998</td>\n",
       "      <td>453.510010</td>\n",
       "      <td>447.299988</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>3023500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>450.679993</td>\n",
       "      <td>450.929993</td>\n",
       "      <td>446.089996</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>3007400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>450.079987</td>\n",
       "      <td>450.320007</td>\n",
       "      <td>445.200012</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>3658400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5364 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Volume  \\\n",
       "0     2000-05-19   96.106028   96.106028   94.484962   94.779701   775500   \n",
       "1     2000-05-22   94.716551   94.716551   92.169162   94.190231  1850600   \n",
       "2     2000-05-23   94.463952   94.463952   92.758675   92.758675   373900   \n",
       "3     2000-05-24   92.800753   94.358660   92.063905   94.148132   400300   \n",
       "4     2000-05-25   94.337613   94.948145   92.884970   93.284973    69600   \n",
       "...          ...         ...         ...         ...         ...      ...   \n",
       "5359  2021-09-08  452.899994  453.679993  450.869995  453.000000  4076800   \n",
       "5360  2021-09-09  452.690002  454.579987  450.730011  450.980011  3851600   \n",
       "5361  2021-09-10  453.059998  453.510010  447.299988  447.540009  3023500   \n",
       "5362  2021-09-13  450.679993  450.929993  446.089996  448.579987  3007400   \n",
       "5363  2021-09-14  450.079987  450.320007  445.200012  446.190002  3658400   \n",
       "\n",
       "      Dividends  Stock Splits  \n",
       "0           0.0             0  \n",
       "1           0.0             0  \n",
       "2           0.0             0  \n",
       "3           0.0             0  \n",
       "4           0.0             0  \n",
       "...         ...           ...  \n",
       "5359        0.0             0  \n",
       "5360        0.0             0  \n",
       "5361        0.0             0  \n",
       "5362        0.0             0  \n",
       "5363        0.0             0  \n",
       "\n",
       "[5364 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add indices for every day in the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = df.Date.min()\n",
    "end_date = df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = pd.date_range(start=start_date, end=end_date).to_frame(name=\"Date\")\n",
    "df_date.reset_index(drop=True, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.merge(df_date, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.interpolate(method='linear', limit_direction='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>94.484962</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>7.755000e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-20</td>\n",
       "      <td>95.642869</td>\n",
       "      <td>95.642869</td>\n",
       "      <td>93.713029</td>\n",
       "      <td>94.583211</td>\n",
       "      <td>1.133867e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-21</td>\n",
       "      <td>95.179710</td>\n",
       "      <td>95.179710</td>\n",
       "      <td>92.941096</td>\n",
       "      <td>94.386721</td>\n",
       "      <td>1.492233e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>92.169162</td>\n",
       "      <td>94.190231</td>\n",
       "      <td>1.850600e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>3.739000e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>453.059998</td>\n",
       "      <td>453.510010</td>\n",
       "      <td>447.299988</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>3.023500e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>452.266663</td>\n",
       "      <td>452.650004</td>\n",
       "      <td>446.896657</td>\n",
       "      <td>447.886668</td>\n",
       "      <td>3.018133e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>451.473328</td>\n",
       "      <td>451.789998</td>\n",
       "      <td>446.493327</td>\n",
       "      <td>448.233327</td>\n",
       "      <td>3.012767e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>450.679993</td>\n",
       "      <td>450.929993</td>\n",
       "      <td>446.089996</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>3.007400e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>450.079987</td>\n",
       "      <td>450.320007</td>\n",
       "      <td>445.200012</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>3.658400e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7789 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close        Volume  \\\n",
       "0    2000-05-19   96.106028   96.106028   94.484962   94.779701  7.755000e+05   \n",
       "1    2000-05-20   95.642869   95.642869   93.713029   94.583211  1.133867e+06   \n",
       "2    2000-05-21   95.179710   95.179710   92.941096   94.386721  1.492233e+06   \n",
       "3    2000-05-22   94.716551   94.716551   92.169162   94.190231  1.850600e+06   \n",
       "4    2000-05-23   94.463952   94.463952   92.758675   92.758675  3.739000e+05   \n",
       "...         ...         ...         ...         ...         ...           ...   \n",
       "7784 2021-09-10  453.059998  453.510010  447.299988  447.540009  3.023500e+06   \n",
       "7785 2021-09-11  452.266663  452.650004  446.896657  447.886668  3.018133e+06   \n",
       "7786 2021-09-12  451.473328  451.789998  446.493327  448.233327  3.012767e+06   \n",
       "7787 2021-09-13  450.679993  450.929993  446.089996  448.579987  3.007400e+06   \n",
       "7788 2021-09-14  450.079987  450.320007  445.200012  446.190002  3.658400e+06   \n",
       "\n",
       "      Dividends  Stock Splits  \n",
       "0           0.0           0.0  \n",
       "1           0.0           0.0  \n",
       "2           0.0           0.0  \n",
       "3           0.0           0.0  \n",
       "4           0.0           0.0  \n",
       "...         ...           ...  \n",
       "7784        0.0           0.0  \n",
       "7785        0.0           0.0  \n",
       "7786        0.0           0.0  \n",
       "7787        0.0           0.0  \n",
       "7788        0.0           0.0  \n",
       "\n",
       "[7789 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove not needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Date', 'Close']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>94.779701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-20</td>\n",
       "      <td>94.583211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-21</td>\n",
       "      <td>94.386721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.190231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>92.758675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>447.540009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>447.886668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>448.233327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>448.579987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>446.190002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7789 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close\n",
       "0    2000-05-19   94.779701\n",
       "1    2000-05-20   94.583211\n",
       "2    2000-05-21   94.386721\n",
       "3    2000-05-22   94.190231\n",
       "4    2000-05-23   92.758675\n",
       "...         ...         ...\n",
       "7784 2021-09-10  447.540009\n",
       "7785 2021-09-11  447.886668\n",
       "7786 2021-09-12  448.233327\n",
       "7787 2021-09-13  448.579987\n",
       "7788 2021-09-14  446.190002\n",
       "\n",
       "[7789 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple Moving Average**\n",
    "* Example periods: 15, 30 or 45 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSMA(data, period, column='Close'):\n",
    "    return data[column].rolling(window=period).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SMA'] = computeSMA(df, period=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exponential Moving Averages**\n",
    "* Example periods: 15, 30 or 45 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEMA(data, period, column='Close'):\n",
    "    return data[column].ewm(span=period, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EMA'] = computeEMA(df, period=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relative Strength Index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRSI(data, period=14, column='Close'):\n",
    "    delta = data[column].diff(1)\n",
    "    delta = delta.dropna()\n",
    "    up = delta.copy()\n",
    "    down = delta.copy()\n",
    "    up[up < 0] = 0\n",
    "    down[down > 0] = 0\n",
    "    data['up'] = up\n",
    "    data['down'] = down\n",
    "    AVG_Gain = computeSMA(data, period, column='up')\n",
    "    AVG_Loss = abs(computeSMA(data, period, column='down'))\n",
    "    RS = AVG_Gain / AVG_Loss\n",
    "    RSI = 100.0 - (100.0 / (1.0 + RS))\n",
    "    return RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RSI'] = computeRSI(df, period=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Moving Average Convergence Divergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD(data, period1=26, period2=12, signal=9, column='Close'):\n",
    "    exp1 = computeEMA(data,period1, column=column)\n",
    "    exp2 = computeEMA(data,period2, column=column)\n",
    "    data['MACD'] = exp2 - exp1\n",
    "    data['Signal Line'] = computeSMA(data, signal, column='MACD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACD(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>SMA</th>\n",
       "      <th>EMA</th>\n",
       "      <th>up</th>\n",
       "      <th>down</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-20</td>\n",
       "      <td>94.583211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.755140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-21</td>\n",
       "      <td>94.386721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.709088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.043451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.190231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.644231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.080392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.408536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.431557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.222617</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>453.257671</td>\n",
       "      <td>451.878931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.440002</td>\n",
       "      <td>30.279938</td>\n",
       "      <td>1.487905</td>\n",
       "      <td>2.619024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>447.886668</td>\n",
       "      <td>452.970782</td>\n",
       "      <td>451.379898</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.313930</td>\n",
       "      <td>1.046934</td>\n",
       "      <td>2.394046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>448.233327</td>\n",
       "      <td>452.662337</td>\n",
       "      <td>450.986577</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.233827</td>\n",
       "      <td>0.717167</td>\n",
       "      <td>2.129901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>452.332335</td>\n",
       "      <td>450.685753</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.029401</td>\n",
       "      <td>0.478284</td>\n",
       "      <td>1.844411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>451.798335</td>\n",
       "      <td>450.123784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.389984</td>\n",
       "      <td>20.440156</td>\n",
       "      <td>0.095020</td>\n",
       "      <td>1.527523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7789 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close         SMA         EMA        up      down  \\\n",
       "0    2000-05-19   94.779701         NaN   94.779701       NaN       NaN   \n",
       "1    2000-05-20   94.583211         NaN   94.755140  0.000000 -0.196490   \n",
       "2    2000-05-21   94.386721         NaN   94.709088  0.000000 -0.196490   \n",
       "3    2000-05-22   94.190231         NaN   94.644231  0.000000 -0.196490   \n",
       "4    2000-05-23   92.758675         NaN   94.408536  0.000000 -1.431557   \n",
       "...         ...         ...         ...         ...       ...       ...   \n",
       "7784 2021-09-10  447.540009  453.257671  451.878931  0.000000 -3.440002   \n",
       "7785 2021-09-11  447.886668  452.970782  451.379898  0.346659  0.000000   \n",
       "7786 2021-09-12  448.233327  452.662337  450.986577  0.346659  0.000000   \n",
       "7787 2021-09-13  448.579987  452.332335  450.685753  0.346659  0.000000   \n",
       "7788 2021-09-14  446.190002  451.798335  450.123784  0.000000 -2.389984   \n",
       "\n",
       "            RSI      MACD  Signal Line  \n",
       "0           NaN  0.000000          NaN  \n",
       "1           NaN -0.015674          NaN  \n",
       "2           NaN -0.043451          NaN  \n",
       "3           NaN -0.080392          NaN  \n",
       "4           NaN -0.222617          NaN  \n",
       "...         ...       ...          ...  \n",
       "7784  30.279938  1.487905     2.619024  \n",
       "7785  28.313930  1.046934     2.394046  \n",
       "7786  26.233827  0.717167     2.129901  \n",
       "7787  24.029401  0.478284     1.844411  \n",
       "7788  20.440156  0.095020     1.527523  \n",
       "\n",
       "[7789 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>SMA</th>\n",
       "      <th>EMA</th>\n",
       "      <th>up</th>\n",
       "      <th>down</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2000-06-02</td>\n",
       "      <td>99.663971</td>\n",
       "      <td>94.910938</td>\n",
       "      <td>95.600925</td>\n",
       "      <td>1.936874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.245582</td>\n",
       "      <td>0.680463</td>\n",
       "      <td>-0.042866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2000-06-03</td>\n",
       "      <td>99.446431</td>\n",
       "      <td>95.222053</td>\n",
       "      <td>96.081613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217539</td>\n",
       "      <td>71.115354</td>\n",
       "      <td>0.916439</td>\n",
       "      <td>0.090681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2000-06-04</td>\n",
       "      <td>99.228892</td>\n",
       "      <td>95.531765</td>\n",
       "      <td>96.475023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217539</td>\n",
       "      <td>70.985601</td>\n",
       "      <td>1.073524</td>\n",
       "      <td>0.250695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2000-06-05</td>\n",
       "      <td>99.011353</td>\n",
       "      <td>95.840074</td>\n",
       "      <td>96.792064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217539</td>\n",
       "      <td>70.856321</td>\n",
       "      <td>1.167008</td>\n",
       "      <td>0.420929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2000-06-06</td>\n",
       "      <td>98.506065</td>\n",
       "      <td>96.127796</td>\n",
       "      <td>97.006314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.505287</td>\n",
       "      <td>77.029581</td>\n",
       "      <td>1.186644</td>\n",
       "      <td>0.585988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>453.257671</td>\n",
       "      <td>451.878931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.440002</td>\n",
       "      <td>30.279938</td>\n",
       "      <td>1.487905</td>\n",
       "      <td>2.619024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>447.886668</td>\n",
       "      <td>452.970782</td>\n",
       "      <td>451.379898</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.313930</td>\n",
       "      <td>1.046934</td>\n",
       "      <td>2.394046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>448.233327</td>\n",
       "      <td>452.662337</td>\n",
       "      <td>450.986577</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.233827</td>\n",
       "      <td>0.717167</td>\n",
       "      <td>2.129901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>452.332335</td>\n",
       "      <td>450.685753</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.029401</td>\n",
       "      <td>0.478284</td>\n",
       "      <td>1.844411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>451.798335</td>\n",
       "      <td>450.123784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.389984</td>\n",
       "      <td>20.440156</td>\n",
       "      <td>0.095020</td>\n",
       "      <td>1.527523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7775 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close         SMA         EMA        up      down  \\\n",
       "14   2000-06-02   99.663971   94.910938   95.600925  1.936874  0.000000   \n",
       "15   2000-06-03   99.446431   95.222053   96.081613  0.000000 -0.217539   \n",
       "16   2000-06-04   99.228892   95.531765   96.475023  0.000000 -0.217539   \n",
       "17   2000-06-05   99.011353   95.840074   96.792064  0.000000 -0.217539   \n",
       "18   2000-06-06   98.506065   96.127796   97.006314  0.000000 -0.505287   \n",
       "...         ...         ...         ...         ...       ...       ...   \n",
       "7784 2021-09-10  447.540009  453.257671  451.878931  0.000000 -3.440002   \n",
       "7785 2021-09-11  447.886668  452.970782  451.379898  0.346659  0.000000   \n",
       "7786 2021-09-12  448.233327  452.662337  450.986577  0.346659  0.000000   \n",
       "7787 2021-09-13  448.579987  452.332335  450.685753  0.346659  0.000000   \n",
       "7788 2021-09-14  446.190002  451.798335  450.123784  0.000000 -2.389984   \n",
       "\n",
       "            RSI      MACD  Signal Line  \n",
       "14    71.245582  0.680463    -0.042866  \n",
       "15    71.115354  0.916439     0.090681  \n",
       "16    70.985601  1.073524     0.250695  \n",
       "17    70.856321  1.167008     0.420929  \n",
       "18    77.029581  1.186644     0.585988  \n",
       "...         ...       ...          ...  \n",
       "7784  30.279938  1.487905     2.619024  \n",
       "7785  28.313930  1.046934     2.394046  \n",
       "7786  26.233827  0.717167     2.129901  \n",
       "7787  24.029401  0.478284     1.844411  \n",
       "7788  20.440156  0.095020     1.527523  \n",
       "\n",
       "[7775 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq1 = df['SMA'].values\n",
    "in_seq2 = df['EMA'].values\n",
    "in_seq3 = df['RSI'].values\n",
    "in_seq4 = df['MACD'].values\n",
    "in_seq5 = df['Signal Line'].values\n",
    "out_seq = df['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "in_seq3 = in_seq3.reshape((len(in_seq3), 1))\n",
    "in_seq4 = in_seq4.reshape((len(in_seq4), 1))\n",
    "in_seq5 = in_seq5.reshape((len(in_seq5), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.hstack((in_seq1, in_seq2, in_seq3, in_seq4, in_seq5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset)\n",
    "dataset = scaler.transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimensionality reduction - PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca = pca.transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive feature elimination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVR(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = RFE(estimator, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(dataset_pca, out_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: [ True  True False False False]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Selected features: {selector.support_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features ranking: [1 1 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features ranking: {selector.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9993543829868292\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score: {selector.score(dataset_pca, out_seq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = selector.transform(dataset_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.hstack((dataset, out_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a number of time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate a multivariate sequence into samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # Find the end of the pattern\n",
    "        end_ix = i + n_steps\n",
    "        # Check if we are bound by sequence\n",
    "        if end_ix > len(sequences) - 1:\n",
    "            break\n",
    "        # Gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert into input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequences(dataset, n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset knows the number of the features, e.g. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = n_steps\n",
    "prediction_size = n_features\n",
    "y_test = y[-test_size-prediction_size:-prediction_size]\n",
    "X_test = X[-test_size-prediction_size:-prediction_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_expected = y[-prediction_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[:-test_size-prediction_size]\n",
    "X = X[:-test_size-prediction_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define model**\n",
    "\n",
    "Keras Random Search - optimize: LSTM units, Dropout Rate, Learning Rate, Sequence Length\n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    hp_units_1 = hp.Int('units_1', min_value=10, max_value=250, step=10)\n",
    "    model.add(LSTM(hp_units_1, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    \n",
    "    dropout_rate_1 = hp.Float('dropout_1', 0, 0.9, step=0.1, default=0.5)\n",
    "    model.add(Dropout(dropout_rate_1))\n",
    "    \n",
    "    hp_units_2 = hp.Int('units_2', min_value=10, max_value=250, step=10)\n",
    "    model.add(LSTM(hp_units_2, activation='relu'))\n",
    "    \n",
    "    dropout_rate_2 = hp.Float('dropout_2', 0, 0.9, step=0.1, default=0.5)\n",
    "    model.add(Dropout(dropout_rate_2))\n",
    "    \n",
    "    model.add(Dense(n_features))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(model_builder,\n",
    "                        objective='loss',\n",
    "                        max_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 01m 27s]\n",
      "loss: 684.8142700195312\n",
      "\n",
      "Best loss So Far: 21.678747177124023\n",
      "Total elapsed time: 03h 09m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X, y, epochs=100, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of LSTM units are 240 and 90 \n",
      "The dropouts are 0.0 and 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The optimal number of LSTM units are {best_hps.get('units_1')} and {best_hps.get('units_2')} \")\n",
    "print(f\"The dropouts are {best_hps.get('dropout_1')} and {best_hps.get('dropout_2')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with the optimal hyperparameters and train it on the data for 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 3029.3499\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 37.7672\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 37.3084\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 51.3380\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 24.4755\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 44.3317\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 37.5648\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 37.3233\n",
      "Epoch 9/100\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 28.7187\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 27.0038\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 40.2537\n",
      "Epoch 12/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 28.3682\n",
      "Epoch 13/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 34.6914\n",
      "Epoch 14/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 32.1434\n",
      "Epoch 15/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 26.6470\n",
      "Epoch 16/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 29.6923\n",
      "Epoch 17/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 23.7142\n",
      "Epoch 18/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 39.5042\n",
      "Epoch 19/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 26.7618\n",
      "Epoch 20/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 32.4351\n",
      "Epoch 21/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 24.3684\n",
      "Epoch 22/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 28.6180\n",
      "Epoch 23/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 26.6654\n",
      "Epoch 24/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 24.4231\n",
      "Epoch 25/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 29.4760\n",
      "Epoch 26/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 39.2612\n",
      "Epoch 27/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 22.6452\n",
      "Epoch 28/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 23.6900\n",
      "Epoch 29/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 25.1102\n",
      "Epoch 30/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 30.8861\n",
      "Epoch 31/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 25.4304\n",
      "Epoch 32/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 24.5027\n",
      "Epoch 33/100\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 33.9296\n",
      "Epoch 34/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 20.6257\n",
      "Epoch 35/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 26.5446\n",
      "Epoch 36/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 29.9965\n",
      "Epoch 37/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 21.0252\n",
      "Epoch 38/100\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 25.3226\n",
      "Epoch 39/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 22.4729\n",
      "Epoch 40/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 20.0661\n",
      "Epoch 41/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 21.0637\n",
      "Epoch 42/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 27.6975\n",
      "Epoch 43/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 29.5616\n",
      "Epoch 44/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 23.5897\n",
      "Epoch 45/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 23.1836\n",
      "Epoch 46/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 17.7174\n",
      "Epoch 47/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 19.5719\n",
      "Epoch 48/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 28.8980\n",
      "Epoch 49/100\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 25.8443\n",
      "Epoch 50/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 24.6323\n",
      "Epoch 51/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 17.8525\n",
      "Epoch 52/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 17.8546\n",
      "Epoch 53/100\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 16.7098\n",
      "Epoch 54/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 17.3462\n",
      "Epoch 55/100\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 21.8615\n",
      "Epoch 56/100\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 15.4116\n",
      "Epoch 57/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 18.3942\n",
      "Epoch 58/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 18.6563\n",
      "Epoch 59/100\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 15.4747\n",
      "Epoch 60/100\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 19.5949\n",
      "Epoch 61/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 19.1526\n",
      "Epoch 62/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 16.1486\n",
      "Epoch 63/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 14.2963\n",
      "Epoch 64/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 18.3281\n",
      "Epoch 65/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 16.5565\n",
      "Epoch 66/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 15.5110\n",
      "Epoch 67/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 18.2479\n",
      "Epoch 68/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 15.6355\n",
      "Epoch 69/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 15.6987\n",
      "Epoch 70/100\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 16.2390\n",
      "Epoch 71/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 16.8906\n",
      "Epoch 72/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 14.3188\n",
      "Epoch 73/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 15.8490\n",
      "Epoch 74/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 17.5195\n",
      "Epoch 75/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 16.5908\n",
      "Epoch 76/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 12.5509\n",
      "Epoch 77/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 16.7239\n",
      "Epoch 78/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 14.3049\n",
      "Epoch 79/100\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 16.6363\n",
      "Epoch 80/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 12.1285\n",
      "Epoch 81/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 15.8983\n",
      "Epoch 82/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 14.3044\n",
      "Epoch 83/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 14.8364\n",
      "Epoch 84/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 12.9350\n",
      "Epoch 85/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 13.6024\n",
      "Epoch 86/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 14.0022\n",
      "Epoch 87/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 15.8135\n",
      "Epoch 88/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 12.0552\n",
      "Epoch 89/100\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 17.9581\n",
      "Epoch 90/100\n",
      "243/243 [==============================] - 7s 31ms/step - loss: 11.3851\n",
      "Epoch 91/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 11.8822\n",
      "Epoch 92/100\n",
      "243/243 [==============================] - 8s 34ms/step - loss: 13.6934\n",
      "Epoch 93/100\n",
      "243/243 [==============================] - 8s 34ms/step - loss: 11.2140\n",
      "Epoch 94/100\n",
      "243/243 [==============================] - 8s 34ms/step - loss: 10.9387\n",
      "Epoch 95/100\n",
      "243/243 [==============================] - 8s 34ms/step - loss: 12.4006\n",
      "Epoch 96/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 13.7767\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 8s 34ms/step - loss: 12.1134\n",
      "Epoch 98/100\n",
      "243/243 [==============================] - 8s 34ms/step - loss: 12.3500\n",
      "Epoch 99/100\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 11.3429\n",
      "Epoch 100/100\n",
      "243/243 [==============================] - 8s 34ms/step - loss: 13.5914\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 94\n"
     ]
    }
   ],
   "source": [
    "loss_per_epoch = history.history['loss']\n",
    "best_epoch = loss_per_epoch.index(min(loss_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 7763.2295\n",
      "Epoch 2/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 51.8030\n",
      "Epoch 3/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 28.5841\n",
      "Epoch 4/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 24.8138\n",
      "Epoch 5/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 23.4807\n",
      "Epoch 6/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 25.3164\n",
      "Epoch 7/94\n",
      "243/243 [==============================] - 8s 34ms/step - loss: 36.1594\n",
      "Epoch 8/94\n",
      "243/243 [==============================] - 8s 34ms/step - loss: 24.9910\n",
      "Epoch 9/94\n",
      "243/243 [==============================] - 8s 34ms/step - loss: 20.3243\n",
      "Epoch 10/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 23.7286\n",
      "Epoch 11/94\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 32.2316\n",
      "Epoch 12/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 29.2448\n",
      "Epoch 13/94\n",
      "243/243 [==============================] - 9s 36ms/step - loss: 22.3709\n",
      "Epoch 14/94\n",
      "243/243 [==============================] - 9s 36ms/step - loss: 23.8465\n",
      "Epoch 15/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 26.6496\n",
      "Epoch 16/94\n",
      "243/243 [==============================] - 9s 36ms/step - loss: 38.0996\n",
      "Epoch 17/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 24.5907\n",
      "Epoch 18/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 25.5636\n",
      "Epoch 19/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 22.4382\n",
      "Epoch 20/94\n",
      "243/243 [==============================] - 9s 36ms/step - loss: 23.1180\n",
      "Epoch 21/94\n",
      "243/243 [==============================] - 9s 36ms/step - loss: 22.7947\n",
      "Epoch 22/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 32.0012\n",
      "Epoch 23/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 29.2902\n",
      "Epoch 24/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 27.0045\n",
      "Epoch 25/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 27.5404\n",
      "Epoch 26/94\n",
      "243/243 [==============================] - 9s 36ms/step - loss: 28.0115\n",
      "Epoch 27/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 25.8549\n",
      "Epoch 28/94\n",
      "243/243 [==============================] - 9s 36ms/step - loss: 24.7651\n",
      "Epoch 29/94\n",
      "243/243 [==============================] - 9s 36ms/step - loss: 23.9264\n",
      "Epoch 30/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 21.8429\n",
      "Epoch 31/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 31.4518\n",
      "Epoch 32/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 25.3273\n",
      "Epoch 33/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 25.0207\n",
      "Epoch 34/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 20.6884\n",
      "Epoch 35/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 20.2336\n",
      "Epoch 36/94\n",
      "243/243 [==============================] - 9s 36ms/step - loss: 24.5960\n",
      "Epoch 37/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 23.0619\n",
      "Epoch 38/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 21.9108\n",
      "Epoch 39/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 23.6937\n",
      "Epoch 40/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 17.4094\n",
      "Epoch 41/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 17.5035\n",
      "Epoch 42/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 35.3617\n",
      "Epoch 43/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 18.5772\n",
      "Epoch 44/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 16.7451\n",
      "Epoch 45/94\n",
      "243/243 [==============================] - 8s 34ms/step - loss: 18.0330\n",
      "Epoch 46/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 15.8309\n",
      "Epoch 47/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 20.9572\n",
      "Epoch 48/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 22.7397\n",
      "Epoch 49/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 19.2144\n",
      "Epoch 50/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 15.4565\n",
      "Epoch 51/94\n",
      "243/243 [==============================] - 8s 35ms/step - loss: 22.3802\n",
      "Epoch 52/94\n",
      "243/243 [==============================] - 9s 35ms/step - loss: 18.6000\n",
      "Epoch 53/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 21.0618\n",
      "Epoch 54/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 19.0797\n",
      "Epoch 55/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 17.1937\n",
      "Epoch 56/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 15.5156\n",
      "Epoch 57/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 13.1452\n",
      "Epoch 58/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 17.1674\n",
      "Epoch 59/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 15.9491\n",
      "Epoch 60/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 15.7719\n",
      "Epoch 61/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 16.2888\n",
      "Epoch 62/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 16.3004\n",
      "Epoch 63/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 26.1196\n",
      "Epoch 64/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 11.2410\n",
      "Epoch 65/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 14.5484\n",
      "Epoch 66/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 17.1133\n",
      "Epoch 67/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 17.3654\n",
      "Epoch 68/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 14.2180\n",
      "Epoch 69/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 13.4160\n",
      "Epoch 70/94\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 14.7499\n",
      "Epoch 71/94\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 12.9229\n",
      "Epoch 72/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 16.5882\n",
      "Epoch 73/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 12.8433\n",
      "Epoch 74/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 14.2372\n",
      "Epoch 75/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 12.4917\n",
      "Epoch 76/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 13.8609\n",
      "Epoch 77/94\n",
      "243/243 [==============================] - 8s 31ms/step - loss: 11.6769\n",
      "Epoch 78/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 13.0120\n",
      "Epoch 79/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 14.2227\n",
      "Epoch 80/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 16.6181\n",
      "Epoch 81/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 19.1467\n",
      "Epoch 82/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 11.4990\n",
      "Epoch 83/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 11.2966\n",
      "Epoch 84/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 12.2459\n",
      "Epoch 85/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 15.9934\n",
      "Epoch 86/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 10.5388\n",
      "Epoch 87/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 14.8049\n",
      "Epoch 88/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 15.8148\n",
      "Epoch 89/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 13.4725\n",
      "Epoch 90/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 19.3608\n",
      "Epoch 91/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 12.7217\n",
      "Epoch 92/94\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 11.6281\n",
      "Epoch 93/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 12.1197\n",
      "Epoch 94/94\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 12.3272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2da05ca520>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y)\n",
    "plt.plot(yhat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 452.94  Expected: 448.58\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted: {yhat[0][0]:.2f}  Expected: {y_expected[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THIS IS NOT AN INVESTMENT ADVICE!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
