{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Hyperband Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "* [Time Series Forecasting on Stock Prices](https://www.youtube.com/watch?v=j05UUs99eNQ) from [Coding Tech](https://www.youtube.com/channel/UCtxCXg-UvSnTKPOzLH4wJaQ)\n",
    "\n",
    "Related:\n",
    "* https://iknowfirst.com/stock-forecast-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** _Investing in the stock market involves risk and can lead to monetary loss. This material is purely for educational purposes and should not be taken as professional investment advice. Invest at your own discretion._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SP500.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>94.484962</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>775500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>92.169162</td>\n",
       "      <td>94.190231</td>\n",
       "      <td>1850600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>373900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-24</td>\n",
       "      <td>92.800753</td>\n",
       "      <td>94.358660</td>\n",
       "      <td>92.063905</td>\n",
       "      <td>94.148132</td>\n",
       "      <td>400300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-25</td>\n",
       "      <td>94.337613</td>\n",
       "      <td>94.948145</td>\n",
       "      <td>92.884970</td>\n",
       "      <td>93.284973</td>\n",
       "      <td>69600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5359</th>\n",
       "      <td>2021-09-08</td>\n",
       "      <td>452.899994</td>\n",
       "      <td>453.679993</td>\n",
       "      <td>450.869995</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>4076800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5360</th>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>452.690002</td>\n",
       "      <td>454.579987</td>\n",
       "      <td>450.730011</td>\n",
       "      <td>450.980011</td>\n",
       "      <td>3851600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5361</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>453.059998</td>\n",
       "      <td>453.510010</td>\n",
       "      <td>447.299988</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>3023500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>450.679993</td>\n",
       "      <td>450.929993</td>\n",
       "      <td>446.089996</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>3007400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>450.079987</td>\n",
       "      <td>450.320007</td>\n",
       "      <td>445.200012</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>3658400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5364 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Volume  \\\n",
       "0     2000-05-19   96.106028   96.106028   94.484962   94.779701   775500   \n",
       "1     2000-05-22   94.716551   94.716551   92.169162   94.190231  1850600   \n",
       "2     2000-05-23   94.463952   94.463952   92.758675   92.758675   373900   \n",
       "3     2000-05-24   92.800753   94.358660   92.063905   94.148132   400300   \n",
       "4     2000-05-25   94.337613   94.948145   92.884970   93.284973    69600   \n",
       "...          ...         ...         ...         ...         ...      ...   \n",
       "5359  2021-09-08  452.899994  453.679993  450.869995  453.000000  4076800   \n",
       "5360  2021-09-09  452.690002  454.579987  450.730011  450.980011  3851600   \n",
       "5361  2021-09-10  453.059998  453.510010  447.299988  447.540009  3023500   \n",
       "5362  2021-09-13  450.679993  450.929993  446.089996  448.579987  3007400   \n",
       "5363  2021-09-14  450.079987  450.320007  445.200012  446.190002  3658400   \n",
       "\n",
       "      Dividends  Stock Splits  \n",
       "0           0.0             0  \n",
       "1           0.0             0  \n",
       "2           0.0             0  \n",
       "3           0.0             0  \n",
       "4           0.0             0  \n",
       "...         ...           ...  \n",
       "5359        0.0             0  \n",
       "5360        0.0             0  \n",
       "5361        0.0             0  \n",
       "5362        0.0             0  \n",
       "5363        0.0             0  \n",
       "\n",
       "[5364 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add indices for every day in the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = df.Date.min()\n",
    "end_date = df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = pd.date_range(start=start_date, end=end_date).to_frame(name=\"Date\")\n",
    "df_date.reset_index(drop=True, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.merge(df_date, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.interpolate(method='linear', limit_direction='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>94.484962</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>7.755000e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-20</td>\n",
       "      <td>95.642869</td>\n",
       "      <td>95.642869</td>\n",
       "      <td>93.713029</td>\n",
       "      <td>94.583211</td>\n",
       "      <td>1.133867e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-21</td>\n",
       "      <td>95.179710</td>\n",
       "      <td>95.179710</td>\n",
       "      <td>92.941096</td>\n",
       "      <td>94.386721</td>\n",
       "      <td>1.492233e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>92.169162</td>\n",
       "      <td>94.190231</td>\n",
       "      <td>1.850600e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>3.739000e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>453.059998</td>\n",
       "      <td>453.510010</td>\n",
       "      <td>447.299988</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>3.023500e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>452.266663</td>\n",
       "      <td>452.650004</td>\n",
       "      <td>446.896657</td>\n",
       "      <td>447.886668</td>\n",
       "      <td>3.018133e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>451.473328</td>\n",
       "      <td>451.789998</td>\n",
       "      <td>446.493327</td>\n",
       "      <td>448.233327</td>\n",
       "      <td>3.012767e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>450.679993</td>\n",
       "      <td>450.929993</td>\n",
       "      <td>446.089996</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>3.007400e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>450.079987</td>\n",
       "      <td>450.320007</td>\n",
       "      <td>445.200012</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>3.658400e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7789 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close        Volume  \\\n",
       "0    2000-05-19   96.106028   96.106028   94.484962   94.779701  7.755000e+05   \n",
       "1    2000-05-20   95.642869   95.642869   93.713029   94.583211  1.133867e+06   \n",
       "2    2000-05-21   95.179710   95.179710   92.941096   94.386721  1.492233e+06   \n",
       "3    2000-05-22   94.716551   94.716551   92.169162   94.190231  1.850600e+06   \n",
       "4    2000-05-23   94.463952   94.463952   92.758675   92.758675  3.739000e+05   \n",
       "...         ...         ...         ...         ...         ...           ...   \n",
       "7784 2021-09-10  453.059998  453.510010  447.299988  447.540009  3.023500e+06   \n",
       "7785 2021-09-11  452.266663  452.650004  446.896657  447.886668  3.018133e+06   \n",
       "7786 2021-09-12  451.473328  451.789998  446.493327  448.233327  3.012767e+06   \n",
       "7787 2021-09-13  450.679993  450.929993  446.089996  448.579987  3.007400e+06   \n",
       "7788 2021-09-14  450.079987  450.320007  445.200012  446.190002  3.658400e+06   \n",
       "\n",
       "      Dividends  Stock Splits  \n",
       "0           0.0           0.0  \n",
       "1           0.0           0.0  \n",
       "2           0.0           0.0  \n",
       "3           0.0           0.0  \n",
       "4           0.0           0.0  \n",
       "...         ...           ...  \n",
       "7784        0.0           0.0  \n",
       "7785        0.0           0.0  \n",
       "7786        0.0           0.0  \n",
       "7787        0.0           0.0  \n",
       "7788        0.0           0.0  \n",
       "\n",
       "[7789 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove not needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Date', 'Close']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>94.779701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-20</td>\n",
       "      <td>94.583211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-21</td>\n",
       "      <td>94.386721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.190231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>92.758675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>447.540009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>447.886668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>448.233327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>448.579987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>446.190002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7789 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close\n",
       "0    2000-05-19   94.779701\n",
       "1    2000-05-20   94.583211\n",
       "2    2000-05-21   94.386721\n",
       "3    2000-05-22   94.190231\n",
       "4    2000-05-23   92.758675\n",
       "...         ...         ...\n",
       "7784 2021-09-10  447.540009\n",
       "7785 2021-09-11  447.886668\n",
       "7786 2021-09-12  448.233327\n",
       "7787 2021-09-13  448.579987\n",
       "7788 2021-09-14  446.190002\n",
       "\n",
       "[7789 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple Moving Average**\n",
    "* Example periods: 15, 30 or 45 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSMA(data, period, column='Close'):\n",
    "    return data[column].rolling(window=period).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SMA'] = computeSMA(df, period=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exponential Moving Averages**\n",
    "* Example periods: 15, 30 or 45 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEMA(data, period, column='Close'):\n",
    "    return data[column].ewm(span=period, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EMA'] = computeEMA(df, period=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relative Strength Index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRSI(data, period=14, column='Close'):\n",
    "    delta = data[column].diff(1)\n",
    "    delta = delta.dropna()\n",
    "    up = delta.copy()\n",
    "    down = delta.copy()\n",
    "    up[up < 0] = 0\n",
    "    down[down > 0] = 0\n",
    "    data['up'] = up\n",
    "    data['down'] = down\n",
    "    AVG_Gain = computeSMA(data, period, column='up')\n",
    "    AVG_Loss = abs(computeSMA(data, period, column='down'))\n",
    "    RS = AVG_Gain / AVG_Loss\n",
    "    RSI = 100.0 - (100.0 / (1.0 + RS))\n",
    "    return RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RSI'] = computeRSI(df, period=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Moving Average Convergence Divergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD(data, period1=26, period2=12, signal=9, column='Close'):\n",
    "    exp1 = computeEMA(data,period1, column=column)\n",
    "    exp2 = computeEMA(data,period2, column=column)\n",
    "    data['MACD'] = exp2 - exp1\n",
    "    data['Signal Line'] = computeSMA(data, signal, column='MACD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACD(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>SMA</th>\n",
       "      <th>EMA</th>\n",
       "      <th>up</th>\n",
       "      <th>down</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-20</td>\n",
       "      <td>94.583211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.755140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-21</td>\n",
       "      <td>94.386721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.709088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.043451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.190231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.644231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.080392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.408536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.431557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.222617</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>453.257671</td>\n",
       "      <td>451.878931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.440002</td>\n",
       "      <td>30.279938</td>\n",
       "      <td>1.487905</td>\n",
       "      <td>2.619024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>447.886668</td>\n",
       "      <td>452.970782</td>\n",
       "      <td>451.379898</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.313930</td>\n",
       "      <td>1.046934</td>\n",
       "      <td>2.394046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>448.233327</td>\n",
       "      <td>452.662337</td>\n",
       "      <td>450.986577</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.233827</td>\n",
       "      <td>0.717167</td>\n",
       "      <td>2.129901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>452.332335</td>\n",
       "      <td>450.685753</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.029401</td>\n",
       "      <td>0.478284</td>\n",
       "      <td>1.844411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>451.798335</td>\n",
       "      <td>450.123784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.389984</td>\n",
       "      <td>20.440156</td>\n",
       "      <td>0.095020</td>\n",
       "      <td>1.527523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7789 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close         SMA         EMA        up      down  \\\n",
       "0    2000-05-19   94.779701         NaN   94.779701       NaN       NaN   \n",
       "1    2000-05-20   94.583211         NaN   94.755140  0.000000 -0.196490   \n",
       "2    2000-05-21   94.386721         NaN   94.709088  0.000000 -0.196490   \n",
       "3    2000-05-22   94.190231         NaN   94.644231  0.000000 -0.196490   \n",
       "4    2000-05-23   92.758675         NaN   94.408536  0.000000 -1.431557   \n",
       "...         ...         ...         ...         ...       ...       ...   \n",
       "7784 2021-09-10  447.540009  453.257671  451.878931  0.000000 -3.440002   \n",
       "7785 2021-09-11  447.886668  452.970782  451.379898  0.346659  0.000000   \n",
       "7786 2021-09-12  448.233327  452.662337  450.986577  0.346659  0.000000   \n",
       "7787 2021-09-13  448.579987  452.332335  450.685753  0.346659  0.000000   \n",
       "7788 2021-09-14  446.190002  451.798335  450.123784  0.000000 -2.389984   \n",
       "\n",
       "            RSI      MACD  Signal Line  \n",
       "0           NaN  0.000000          NaN  \n",
       "1           NaN -0.015674          NaN  \n",
       "2           NaN -0.043451          NaN  \n",
       "3           NaN -0.080392          NaN  \n",
       "4           NaN -0.222617          NaN  \n",
       "...         ...       ...          ...  \n",
       "7784  30.279938  1.487905     2.619024  \n",
       "7785  28.313930  1.046934     2.394046  \n",
       "7786  26.233827  0.717167     2.129901  \n",
       "7787  24.029401  0.478284     1.844411  \n",
       "7788  20.440156  0.095020     1.527523  \n",
       "\n",
       "[7789 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>SMA</th>\n",
       "      <th>EMA</th>\n",
       "      <th>up</th>\n",
       "      <th>down</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2000-06-02</td>\n",
       "      <td>99.663971</td>\n",
       "      <td>94.910938</td>\n",
       "      <td>95.600925</td>\n",
       "      <td>1.936874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.245582</td>\n",
       "      <td>0.680463</td>\n",
       "      <td>-0.042866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2000-06-03</td>\n",
       "      <td>99.446431</td>\n",
       "      <td>95.222053</td>\n",
       "      <td>96.081613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217539</td>\n",
       "      <td>71.115354</td>\n",
       "      <td>0.916439</td>\n",
       "      <td>0.090681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2000-06-04</td>\n",
       "      <td>99.228892</td>\n",
       "      <td>95.531765</td>\n",
       "      <td>96.475023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217539</td>\n",
       "      <td>70.985601</td>\n",
       "      <td>1.073524</td>\n",
       "      <td>0.250695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2000-06-05</td>\n",
       "      <td>99.011353</td>\n",
       "      <td>95.840074</td>\n",
       "      <td>96.792064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217539</td>\n",
       "      <td>70.856321</td>\n",
       "      <td>1.167008</td>\n",
       "      <td>0.420929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2000-06-06</td>\n",
       "      <td>98.506065</td>\n",
       "      <td>96.127796</td>\n",
       "      <td>97.006314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.505287</td>\n",
       "      <td>77.029581</td>\n",
       "      <td>1.186644</td>\n",
       "      <td>0.585988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>453.257671</td>\n",
       "      <td>451.878931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.440002</td>\n",
       "      <td>30.279938</td>\n",
       "      <td>1.487905</td>\n",
       "      <td>2.619024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>447.886668</td>\n",
       "      <td>452.970782</td>\n",
       "      <td>451.379898</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.313930</td>\n",
       "      <td>1.046934</td>\n",
       "      <td>2.394046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>448.233327</td>\n",
       "      <td>452.662337</td>\n",
       "      <td>450.986577</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.233827</td>\n",
       "      <td>0.717167</td>\n",
       "      <td>2.129901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>452.332335</td>\n",
       "      <td>450.685753</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.029401</td>\n",
       "      <td>0.478284</td>\n",
       "      <td>1.844411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>451.798335</td>\n",
       "      <td>450.123784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.389984</td>\n",
       "      <td>20.440156</td>\n",
       "      <td>0.095020</td>\n",
       "      <td>1.527523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7775 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close         SMA         EMA        up      down  \\\n",
       "14   2000-06-02   99.663971   94.910938   95.600925  1.936874  0.000000   \n",
       "15   2000-06-03   99.446431   95.222053   96.081613  0.000000 -0.217539   \n",
       "16   2000-06-04   99.228892   95.531765   96.475023  0.000000 -0.217539   \n",
       "17   2000-06-05   99.011353   95.840074   96.792064  0.000000 -0.217539   \n",
       "18   2000-06-06   98.506065   96.127796   97.006314  0.000000 -0.505287   \n",
       "...         ...         ...         ...         ...       ...       ...   \n",
       "7784 2021-09-10  447.540009  453.257671  451.878931  0.000000 -3.440002   \n",
       "7785 2021-09-11  447.886668  452.970782  451.379898  0.346659  0.000000   \n",
       "7786 2021-09-12  448.233327  452.662337  450.986577  0.346659  0.000000   \n",
       "7787 2021-09-13  448.579987  452.332335  450.685753  0.346659  0.000000   \n",
       "7788 2021-09-14  446.190002  451.798335  450.123784  0.000000 -2.389984   \n",
       "\n",
       "            RSI      MACD  Signal Line  \n",
       "14    71.245582  0.680463    -0.042866  \n",
       "15    71.115354  0.916439     0.090681  \n",
       "16    70.985601  1.073524     0.250695  \n",
       "17    70.856321  1.167008     0.420929  \n",
       "18    77.029581  1.186644     0.585988  \n",
       "...         ...       ...          ...  \n",
       "7784  30.279938  1.487905     2.619024  \n",
       "7785  28.313930  1.046934     2.394046  \n",
       "7786  26.233827  0.717167     2.129901  \n",
       "7787  24.029401  0.478284     1.844411  \n",
       "7788  20.440156  0.095020     1.527523  \n",
       "\n",
       "[7775 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq1 = df['SMA'].values\n",
    "in_seq2 = df['EMA'].values\n",
    "in_seq3 = df['RSI'].values\n",
    "in_seq4 = df['MACD'].values\n",
    "in_seq5 = df['Signal Line'].values\n",
    "out_seq = df['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "in_seq3 = in_seq3.reshape((len(in_seq3), 1))\n",
    "in_seq4 = in_seq4.reshape((len(in_seq4), 1))\n",
    "in_seq5 = in_seq5.reshape((len(in_seq5), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.hstack((in_seq1, in_seq2, in_seq3, in_seq4, in_seq5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset)\n",
    "dataset = scaler.transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimensionality reduction - PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca = pca.transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive feature elimination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVR(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = RFE(estimator, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(dataset_pca, out_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: [ True  True False False False]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Selected features: {selector.support_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features ranking: [1 1 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features ranking: {selector.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9993543829868292\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score: {selector.score(dataset_pca, out_seq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = selector.transform(dataset_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.hstack((dataset, out_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a number of time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate a multivariate sequence into samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # Find the end of the pattern\n",
    "        end_ix = i + n_steps\n",
    "        # Check if we are bound by sequence\n",
    "        if end_ix > len(sequences) - 1:\n",
    "            break\n",
    "        # Gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert into input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequences(dataset, n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset knows the number of the features, e.g. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = n_steps\n",
    "prediction_size = n_features\n",
    "y_test = y[-test_size-prediction_size:-prediction_size]\n",
    "X_test = X[-test_size-prediction_size:-prediction_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_expected = y[-prediction_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[:-test_size-prediction_size]\n",
    "X = X[:-test_size-prediction_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define model**\n",
    "\n",
    "Keras Random Search - optimize: LSTM units, Dropout Rate, Learning Rate, Sequence Length\n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    hp_units_1 = hp.Int('units_1', min_value=10, max_value=250, step=10)\n",
    "    model.add(LSTM(hp_units_1, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    \n",
    "    dropout_rate_1 = hp.Float('dropout_1', 0, 0.9, step=0.1, default=0.5)\n",
    "    model.add(Dropout(dropout_rate_1))\n",
    "    \n",
    "    hp_units_2 = hp.Int('units_2', min_value=10, max_value=250, step=10)\n",
    "    model.add(LSTM(hp_units_2, activation='relu'))\n",
    "    \n",
    "    dropout_rate_2 = hp.Float('dropout_2', 0, 0.9, step=0.1, default=0.5)\n",
    "    model.add(Dropout(dropout_rate_2))\n",
    "    \n",
    "    model.add(Dense(n_features))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='loss',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='ts_test_dir',\n",
    "                     project_name='ts_forecast_tune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 45s]\n",
      "loss: 1756.3858642578125\n",
      "\n",
      "Best loss So Far: 168.2464141845703\n",
      "Total elapsed time: 00h 10m 40s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X, y, epochs=100, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of LSTM units are 40 and 240 \n",
      "The dropouts are 0.30000000000000004 and 0.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"The optimal number of LSTM units are {best_hps.get('units_1')} and {best_hps.get('units_2')} \")\n",
    "print(f\"The dropouts are {best_hps.get('dropout_1')} and {best_hps.get('dropout_2')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with the optimal hyperparameters and train it on the data for 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "243/243 [==============================] - 4s 16ms/step - loss: 3611.4915\n",
      "Epoch 2/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 248.3199\n",
      "Epoch 3/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 181.8274\n",
      "Epoch 4/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 206.0918\n",
      "Epoch 5/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 170.2121\n",
      "Epoch 6/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 187.6500\n",
      "Epoch 7/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 269.9380\n",
      "Epoch 8/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 150.8417\n",
      "Epoch 9/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 167.8600\n",
      "Epoch 10/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 181.5167\n",
      "Epoch 11/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 170.4916\n",
      "Epoch 12/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 187.2389\n",
      "Epoch 13/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 174.7198\n",
      "Epoch 14/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 154.2948\n",
      "Epoch 15/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 136.3098\n",
      "Epoch 16/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 132.9132\n",
      "Epoch 17/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 131.3505\n",
      "Epoch 18/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 121.6211\n",
      "Epoch 19/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 127.8315\n",
      "Epoch 20/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 181.8968\n",
      "Epoch 21/300\n",
      "243/243 [==============================] - 5s 23ms/step - loss: 126.1137\n",
      "Epoch 22/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 132.6462\n",
      "Epoch 23/300\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 130.5441\n",
      "Epoch 24/300\n",
      "243/243 [==============================] - 5s 23ms/step - loss: 133.5255\n",
      "Epoch 25/300\n",
      "243/243 [==============================] - 8s 31ms/step - loss: 100.5984\n",
      "Epoch 26/300\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 109.3977\n",
      "Epoch 27/300\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 122.3924\n",
      "Epoch 28/300\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 109.4980\n",
      "Epoch 29/300\n",
      "243/243 [==============================] - 7s 31ms/step - loss: 109.2306\n",
      "Epoch 30/300\n",
      "243/243 [==============================] - 8s 31ms/step - loss: 99.0737\n",
      "Epoch 31/300\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 102.7638\n",
      "Epoch 32/300\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 107.2465\n",
      "Epoch 33/300\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 160.2665\n",
      "Epoch 34/300\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 95.0144\n",
      "Epoch 35/300\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 106.8244\n",
      "Epoch 36/300\n",
      "243/243 [==============================] - 8s 31ms/step - loss: 107.2060\n",
      "Epoch 37/300\n",
      "243/243 [==============================] - 8s 31ms/step - loss: 87.7619\n",
      "Epoch 38/300\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 115.3689\n",
      "Epoch 39/300\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 74.8513\n",
      "Epoch 40/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 87.9764\n",
      "Epoch 41/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 82.6807\n",
      "Epoch 42/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 100.6832\n",
      "Epoch 43/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 107.2771\n",
      "Epoch 44/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 78.6425\n",
      "Epoch 45/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 75.4679\n",
      "Epoch 46/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 80.7510\n",
      "Epoch 47/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 85.2396\n",
      "Epoch 48/300\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 80.4987\n",
      "Epoch 49/300\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 76.9326\n",
      "Epoch 50/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 80.9082\n",
      "Epoch 51/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 76.0156\n",
      "Epoch 52/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 135.5479\n",
      "Epoch 53/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 95.0240\n",
      "Epoch 54/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 77.3254\n",
      "Epoch 55/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 83.7305\n",
      "Epoch 56/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 67.6436\n",
      "Epoch 57/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 79.7030\n",
      "Epoch 58/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 71.3751\n",
      "Epoch 59/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 83.6563\n",
      "Epoch 60/300\n",
      "243/243 [==============================] - 4s 15ms/step - loss: 67.6446\n",
      "Epoch 61/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 78.2266\n",
      "Epoch 62/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 80.9718\n",
      "Epoch 63/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 73.3400\n",
      "Epoch 64/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 71.1419\n",
      "Epoch 65/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 68.6066\n",
      "Epoch 66/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 61.3322\n",
      "Epoch 67/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 75.6183\n",
      "Epoch 68/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 63.1107\n",
      "Epoch 69/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 67.0791\n",
      "Epoch 70/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 70.2289\n",
      "Epoch 71/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 66.9836\n",
      "Epoch 72/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 61.8205\n",
      "Epoch 73/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 73.8895\n",
      "Epoch 74/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 73.2932\n",
      "Epoch 75/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 70.5769\n",
      "Epoch 76/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 53.0989\n",
      "Epoch 77/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 61.7994\n",
      "Epoch 78/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 56.4780\n",
      "Epoch 79/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 60.5734\n",
      "Epoch 80/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 62.1555\n",
      "Epoch 81/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 60.7301\n",
      "Epoch 82/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 61.1200\n",
      "Epoch 83/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 61.8726\n",
      "Epoch 84/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 56.7502\n",
      "Epoch 85/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 60.5479\n",
      "Epoch 86/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 60.9742\n",
      "Epoch 87/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 59.2666\n",
      "Epoch 88/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 52.8578\n",
      "Epoch 89/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 52.4080\n",
      "Epoch 90/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 69.5907\n",
      "Epoch 91/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 56.0738\n",
      "Epoch 92/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 78.9020\n",
      "Epoch 93/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 56.7755\n",
      "Epoch 94/300\n",
      "243/243 [==============================] - 4s 17ms/step - loss: 53.5488\n",
      "Epoch 95/300\n",
      "243/243 [==============================] - 4s 17ms/step - loss: 52.7002\n",
      "Epoch 96/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 55.7812\n",
      "Epoch 97/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 5s 19ms/step - loss: 59.7574\n",
      "Epoch 98/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 58.6595\n",
      "Epoch 99/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 57.2564\n",
      "Epoch 100/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 53.6202\n",
      "Epoch 101/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 57.1547\n",
      "Epoch 102/300\n",
      "243/243 [==============================] - 4s 17ms/step - loss: 54.4352\n",
      "Epoch 103/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 57.5089\n",
      "Epoch 104/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 80.2439\n",
      "Epoch 105/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 86.4679\n",
      "Epoch 106/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 69.6967\n",
      "Epoch 107/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 63.9534\n",
      "Epoch 108/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 69.8979\n",
      "Epoch 109/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 62.0653\n",
      "Epoch 110/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 61.2827\n",
      "Epoch 111/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 61.6958\n",
      "Epoch 112/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 64.1235\n",
      "Epoch 113/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 60.6896\n",
      "Epoch 114/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 58.8718\n",
      "Epoch 115/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 62.4599\n",
      "Epoch 116/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 57.3191\n",
      "Epoch 117/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 57.5218\n",
      "Epoch 118/300\n",
      "243/243 [==============================] - 4s 17ms/step - loss: 64.9854\n",
      "Epoch 119/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 53.7800\n",
      "Epoch 120/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 57.1100\n",
      "Epoch 121/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 57.7963\n",
      "Epoch 122/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 60.3902\n",
      "Epoch 123/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 59.9564\n",
      "Epoch 124/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 59.1143\n",
      "Epoch 125/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 60.3077\n",
      "Epoch 126/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 54.1557\n",
      "Epoch 127/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 62.6433\n",
      "Epoch 128/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 50.7094\n",
      "Epoch 129/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 60.3202\n",
      "Epoch 130/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 56.8438\n",
      "Epoch 131/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 59.6552\n",
      "Epoch 132/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 61.7052\n",
      "Epoch 133/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 58.4430\n",
      "Epoch 134/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 58.0565\n",
      "Epoch 135/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 57.9753\n",
      "Epoch 136/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 58.5111\n",
      "Epoch 137/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 68.0934\n",
      "Epoch 138/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 65.6037\n",
      "Epoch 139/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 55.0218\n",
      "Epoch 140/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 57.6310\n",
      "Epoch 141/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 56.7764\n",
      "Epoch 142/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 56.2264\n",
      "Epoch 143/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 55.7718\n",
      "Epoch 144/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 54.8676\n",
      "Epoch 145/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 59.7045\n",
      "Epoch 146/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 53.8019\n",
      "Epoch 147/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 51.1601\n",
      "Epoch 148/300\n",
      "243/243 [==============================] - 4s 17ms/step - loss: 52.8672\n",
      "Epoch 149/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 56.2657\n",
      "Epoch 150/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 57.2181\n",
      "Epoch 151/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 54.3821\n",
      "Epoch 152/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 59.3716\n",
      "Epoch 153/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 52.0544\n",
      "Epoch 154/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 55.5127\n",
      "Epoch 155/300\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 57.5672\n",
      "Epoch 156/300\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 56.1786\n",
      "Epoch 157/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 55.6502\n",
      "Epoch 158/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 52.5609\n",
      "Epoch 159/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 53.5438\n",
      "Epoch 160/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 53.9790\n",
      "Epoch 161/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 51.0222\n",
      "Epoch 162/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 60.3503\n",
      "Epoch 163/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 50.2013\n",
      "Epoch 164/300\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 54.5921\n",
      "Epoch 165/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 53.9348\n",
      "Epoch 166/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 49.5765\n",
      "Epoch 167/300\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 49.3305\n",
      "Epoch 168/300\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 51.2029\n",
      "Epoch 169/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 51.2182\n",
      "Epoch 170/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 51.1803\n",
      "Epoch 171/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 53.8956\n",
      "Epoch 172/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 52.0956\n",
      "Epoch 173/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 49.5876\n",
      "Epoch 174/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 51.0203\n",
      "Epoch 175/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 49.5990\n",
      "Epoch 176/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 52.7142\n",
      "Epoch 177/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 51.6393\n",
      "Epoch 178/300\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 61.4796\n",
      "Epoch 179/300\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 55.5866\n",
      "Epoch 180/300\n",
      "243/243 [==============================] - 4s 16ms/step - loss: 60.9562\n",
      "Epoch 181/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 50.5110\n",
      "Epoch 182/300\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 49.7785\n",
      "Epoch 183/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 53.3923\n",
      "Epoch 184/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 50.2708\n",
      "Epoch 185/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 53.3773\n",
      "Epoch 186/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 53.1205\n",
      "Epoch 187/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 58.0253\n",
      "Epoch 188/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 52.7698\n",
      "Epoch 189/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 50.4551\n",
      "Epoch 190/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 49.1370\n",
      "Epoch 191/300\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 51.1622\n",
      "Epoch 192/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 5s 20ms/step - loss: 50.1560\n",
      "Epoch 193/300\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 51.9573\n",
      "Epoch 194/300\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 51.9879\n",
      "Epoch 195/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 50.7745\n",
      "Epoch 196/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 48.7822\n",
      "Epoch 197/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 49.9341\n",
      "Epoch 198/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 46.6622\n",
      "Epoch 199/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 50.3481\n",
      "Epoch 200/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 47.1871\n",
      "Epoch 201/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 49.4234\n",
      "Epoch 202/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 51.1861\n",
      "Epoch 203/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 52.3170\n",
      "Epoch 204/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 49.7890\n",
      "Epoch 205/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 47.4683\n",
      "Epoch 206/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 49.1862\n",
      "Epoch 207/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 50.7382\n",
      "Epoch 208/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 52.0302\n",
      "Epoch 209/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 53.2684\n",
      "Epoch 210/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 47.1006\n",
      "Epoch 211/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 48.2157\n",
      "Epoch 212/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 47.5109\n",
      "Epoch 213/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 52.5255\n",
      "Epoch 214/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 49.5646\n",
      "Epoch 215/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 46.2100\n",
      "Epoch 216/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 49.7864\n",
      "Epoch 217/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 48.3856\n",
      "Epoch 218/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 51.1132\n",
      "Epoch 219/300\n",
      "243/243 [==============================] - 4s 15ms/step - loss: 47.7691\n",
      "Epoch 220/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 49.4307\n",
      "Epoch 221/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 44.9489\n",
      "Epoch 222/300\n",
      "243/243 [==============================] - 5s 23ms/step - loss: 47.6497\n",
      "Epoch 223/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 50.4721\n",
      "Epoch 224/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 49.8669\n",
      "Epoch 225/300\n",
      "243/243 [==============================] - 5s 23ms/step - loss: 49.6360\n",
      "Epoch 226/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 49.1538\n",
      "Epoch 227/300\n",
      "243/243 [==============================] - 5s 23ms/step - loss: 46.4308\n",
      "Epoch 228/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 48.9743\n",
      "Epoch 229/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 46.0802\n",
      "Epoch 230/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 48.6871\n",
      "Epoch 231/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 46.7855\n",
      "Epoch 232/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 47.1304\n",
      "Epoch 233/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 48.6664\n",
      "Epoch 234/300\n",
      "243/243 [==============================] - 5s 23ms/step - loss: 51.0497\n",
      "Epoch 235/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 45.6474\n",
      "Epoch 236/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 51.1686\n",
      "Epoch 237/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 46.1320\n",
      "Epoch 238/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 44.8851\n",
      "Epoch 239/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 46.4378\n",
      "Epoch 240/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 45.8376\n",
      "Epoch 241/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 47.0331\n",
      "Epoch 242/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 48.2127\n",
      "Epoch 243/300\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 49.9702\n",
      "Epoch 244/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 46.3956\n",
      "Epoch 245/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 51.7898\n",
      "Epoch 246/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 48.5415\n",
      "Epoch 247/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 47.0025\n",
      "Epoch 248/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 52.8681\n",
      "Epoch 249/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 48.6322\n",
      "Epoch 250/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 47.8862\n",
      "Epoch 251/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 52.6723\n",
      "Epoch 252/300\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 49.0634\n",
      "Epoch 253/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 47.9923\n",
      "Epoch 254/300\n",
      "243/243 [==============================] - 4s 16ms/step - loss: 46.8797\n",
      "Epoch 255/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 46.2095\n",
      "Epoch 256/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 49.2890\n",
      "Epoch 257/300\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 48.2891\n",
      "Epoch 258/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 46.4635\n",
      "Epoch 259/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 46.6076\n",
      "Epoch 260/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 47.0518\n",
      "Epoch 261/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 51.5402\n",
      "Epoch 262/300\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 49.9938\n",
      "Epoch 263/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 51.8743\n",
      "Epoch 264/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 49.8819\n",
      "Epoch 265/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 46.4408\n",
      "Epoch 266/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 44.1781\n",
      "Epoch 267/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 50.7936\n",
      "Epoch 268/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 49.1420\n",
      "Epoch 269/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 49.4553\n",
      "Epoch 270/300\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 47.8188\n",
      "Epoch 271/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 48.9047\n",
      "Epoch 272/300\n",
      "243/243 [==============================] - 4s 17ms/step - loss: 48.7088\n",
      "Epoch 273/300\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 46.3215\n",
      "Epoch 274/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 45.1662\n",
      "Epoch 275/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 47.4842\n",
      "Epoch 276/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 45.6280\n",
      "Epoch 277/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 47.1768\n",
      "Epoch 278/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 48.0808\n",
      "Epoch 279/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 47.6012\n",
      "Epoch 280/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 44.4469\n",
      "Epoch 281/300\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 45.2052\n",
      "Epoch 282/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 44.1552\n",
      "Epoch 283/300\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 46.9252\n",
      "Epoch 284/300\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 50.3758\n",
      "Epoch 285/300\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 52.1048\n",
      "Epoch 286/300\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 44.8017\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 4s 15ms/step - loss: 56.9442\n",
      "Epoch 288/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 51.0956\n",
      "Epoch 289/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 50.7371\n",
      "Epoch 290/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 51.2108\n",
      "Epoch 291/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 47.2180\n",
      "Epoch 292/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 52.2575\n",
      "Epoch 293/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 48.6886\n",
      "Epoch 294/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 48.9135\n",
      "Epoch 295/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 46.0997\n",
      "Epoch 296/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 50.4784\n",
      "Epoch 297/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 47.3292\n",
      "Epoch 298/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 47.0650\n",
      "Epoch 299/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 47.4653\n",
      "Epoch 300/300\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 50.5322\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X, y, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 282\n"
     ]
    }
   ],
   "source": [
    "loss_per_epoch = history.history['loss']\n",
    "best_epoch = loss_per_epoch.index(min(loss_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/282\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 4083.0854\n",
      "Epoch 2/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 255.1636\n",
      "Epoch 3/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 215.9391\n",
      "Epoch 4/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 176.0590\n",
      "Epoch 5/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 184.4689\n",
      "Epoch 6/282\n",
      "243/243 [==============================] - 4s 17ms/step - loss: 189.3852\n",
      "Epoch 7/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 187.5283\n",
      "Epoch 8/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 180.2393\n",
      "Epoch 9/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 166.5152\n",
      "Epoch 10/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 167.6424\n",
      "Epoch 11/282\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 159.3664\n",
      "Epoch 12/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 215.6169\n",
      "Epoch 13/282\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 146.1946\n",
      "Epoch 14/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 206.7694\n",
      "Epoch 15/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 151.5293\n",
      "Epoch 16/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 141.7560\n",
      "Epoch 17/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 160.8937\n",
      "Epoch 18/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 106.6361\n",
      "Epoch 19/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 129.2170\n",
      "Epoch 20/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 115.3188\n",
      "Epoch 21/282\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 108.3676\n",
      "Epoch 22/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 114.4206\n",
      "Epoch 23/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 99.9224\n",
      "Epoch 24/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 120.3799\n",
      "Epoch 25/282\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 118.7052\n",
      "Epoch 26/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 103.2891\n",
      "Epoch 27/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 134.5149\n",
      "Epoch 28/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 116.1775\n",
      "Epoch 29/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 82.5019\n",
      "Epoch 30/282\n",
      "243/243 [==============================] - 4s 15ms/step - loss: 84.3182\n",
      "Epoch 31/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 95.9265\n",
      "Epoch 32/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 83.7515\n",
      "Epoch 33/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 108.7527\n",
      "Epoch 34/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 84.4013\n",
      "Epoch 35/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 145.4944\n",
      "Epoch 36/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 101.6031\n",
      "Epoch 37/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 91.2538\n",
      "Epoch 38/282\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 99.7842\n",
      "Epoch 39/282\n",
      "243/243 [==============================] - 4s 17ms/step - loss: 112.5272\n",
      "Epoch 40/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 90.8864\n",
      "Epoch 41/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 83.5025\n",
      "Epoch 42/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 81.3547\n",
      "Epoch 43/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 85.9483\n",
      "Epoch 44/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 98.3793\n",
      "Epoch 45/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 80.1859\n",
      "Epoch 46/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 118.3274\n",
      "Epoch 47/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 126.8692\n",
      "Epoch 48/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 77.6774\n",
      "Epoch 49/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 80.3806\n",
      "Epoch 50/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 88.3167\n",
      "Epoch 51/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 88.2954\n",
      "Epoch 52/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 88.3438\n",
      "Epoch 53/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 83.8917\n",
      "Epoch 54/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 76.6757\n",
      "Epoch 55/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 77.5984\n",
      "Epoch 56/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 71.7922\n",
      "Epoch 57/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 91.1333\n",
      "Epoch 58/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 69.7072\n",
      "Epoch 59/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 86.9198\n",
      "Epoch 60/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 71.8770\n",
      "Epoch 61/282\n",
      "243/243 [==============================] - 5s 21ms/step - loss: 72.0002\n",
      "Epoch 62/282\n",
      "243/243 [==============================] - 4s 15ms/step - loss: 73.4923\n",
      "Epoch 63/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 76.7165\n",
      "Epoch 64/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 71.5696\n",
      "Epoch 65/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 85.8425\n",
      "Epoch 66/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 67.9247\n",
      "Epoch 67/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 62.5562\n",
      "Epoch 68/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 69.9121\n",
      "Epoch 69/282\n",
      "243/243 [==============================] - 4s 19ms/step - loss: 85.2225\n",
      "Epoch 70/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 92.9610\n",
      "Epoch 71/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 70.8400\n",
      "Epoch 72/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 62.0246\n",
      "Epoch 73/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 66.1970\n",
      "Epoch 74/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 73.8663\n",
      "Epoch 75/282\n",
      "243/243 [==============================] - 4s 19ms/step - loss: 67.5784\n",
      "Epoch 76/282\n",
      "243/243 [==============================] - 4s 19ms/step - loss: 60.7217\n",
      "Epoch 77/282\n",
      "243/243 [==============================] - 4s 19ms/step - loss: 64.4065\n",
      "Epoch 78/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 63.3484\n",
      "Epoch 79/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 61.4921\n",
      "Epoch 80/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 72.7893\n",
      "Epoch 81/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 69.9612\n",
      "Epoch 82/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 66.1563\n",
      "Epoch 83/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 63.6041\n",
      "Epoch 84/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 69.6164\n",
      "Epoch 85/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 63.8384\n",
      "Epoch 86/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 63.3606\n",
      "Epoch 87/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 61.2602\n",
      "Epoch 88/282\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 62.3896\n",
      "Epoch 89/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 69.8300\n",
      "Epoch 90/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 69.9176\n",
      "Epoch 91/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 76.9995\n",
      "Epoch 92/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 58.0696\n",
      "Epoch 93/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 82.3802\n",
      "Epoch 94/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 61.4994\n",
      "Epoch 95/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 63.1724\n",
      "Epoch 96/282\n",
      "243/243 [==============================] - 9s 37ms/step - loss: 60.3653\n",
      "Epoch 97/282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 8s 33ms/step - loss: 57.7514\n",
      "Epoch 98/282\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 64.8717\n",
      "Epoch 99/282\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 58.5783\n",
      "Epoch 100/282\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 60.2837\n",
      "Epoch 101/282\n",
      "243/243 [==============================] - 8s 31ms/step - loss: 70.6392\n",
      "Epoch 102/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 61.9375\n",
      "Epoch 103/282\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 58.6554\n",
      "Epoch 104/282\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 59.3056\n",
      "Epoch 105/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 57.9287\n",
      "Epoch 106/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 57.9622\n",
      "Epoch 107/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 69.9938\n",
      "Epoch 108/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 64.9071\n",
      "Epoch 109/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 57.7678\n",
      "Epoch 110/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 58.3349\n",
      "Epoch 111/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 72.7793\n",
      "Epoch 112/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 72.2013\n",
      "Epoch 113/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 64.2402\n",
      "Epoch 114/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 65.1880\n",
      "Epoch 115/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 68.2400\n",
      "Epoch 116/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 60.8704\n",
      "Epoch 117/282\n",
      "243/243 [==============================] - 8s 33ms/step - loss: 65.1383\n",
      "Epoch 118/282\n",
      "243/243 [==============================] - 8s 31ms/step - loss: 58.5466\n",
      "Epoch 119/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 54.5042\n",
      "Epoch 120/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 57.8184\n",
      "Epoch 121/282\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 60.0823\n",
      "Epoch 122/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 53.2047\n",
      "Epoch 123/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 58.6107\n",
      "Epoch 124/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 66.5058\n",
      "Epoch 125/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 70.8344\n",
      "Epoch 126/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 61.3699\n",
      "Epoch 127/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 58.5415\n",
      "Epoch 128/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 62.2237\n",
      "Epoch 129/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 60.5414\n",
      "Epoch 130/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 57.8104\n",
      "Epoch 131/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 53.8906\n",
      "Epoch 132/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 57.7324\n",
      "Epoch 133/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 53.8554\n",
      "Epoch 134/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 55.2454\n",
      "Epoch 135/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 58.7579\n",
      "Epoch 136/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 60.3253\n",
      "Epoch 137/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 58.5420\n",
      "Epoch 138/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 54.5659\n",
      "Epoch 139/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 59.5459\n",
      "Epoch 140/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 53.2614\n",
      "Epoch 141/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 55.6690\n",
      "Epoch 142/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 63.1636\n",
      "Epoch 143/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 55.3120\n",
      "Epoch 144/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 55.8761\n",
      "Epoch 145/282\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 54.3519\n",
      "Epoch 146/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 57.2868\n",
      "Epoch 147/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 57.0664\n",
      "Epoch 148/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 58.0923\n",
      "Epoch 149/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 58.0054\n",
      "Epoch 150/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 58.3012\n",
      "Epoch 151/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 56.7974\n",
      "Epoch 152/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 62.5679\n",
      "Epoch 153/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 52.6961\n",
      "Epoch 154/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 57.6952\n",
      "Epoch 155/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 53.9563\n",
      "Epoch 156/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 79.8481\n",
      "Epoch 157/282\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 72.1886\n",
      "Epoch 158/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 67.3201\n",
      "Epoch 159/282\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 59.5250\n",
      "Epoch 160/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 62.2129\n",
      "Epoch 161/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 64.4689\n",
      "Epoch 162/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 58.0989\n",
      "Epoch 163/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 61.2549\n",
      "Epoch 164/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 60.3182\n",
      "Epoch 165/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 61.1518\n",
      "Epoch 166/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 55.0717\n",
      "Epoch 167/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 55.5529\n",
      "Epoch 168/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 56.8504\n",
      "Epoch 169/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 55.0940\n",
      "Epoch 170/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 54.6009\n",
      "Epoch 171/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 56.9420\n",
      "Epoch 172/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 57.7542\n",
      "Epoch 173/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 61.4455\n",
      "Epoch 174/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 54.3968\n",
      "Epoch 175/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 54.7150\n",
      "Epoch 176/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 58.1647\n",
      "Epoch 177/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 57.4193\n",
      "Epoch 178/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 50.3023\n",
      "Epoch 179/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 64.2135\n",
      "Epoch 180/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 65.2794\n",
      "Epoch 181/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 52.9149\n",
      "Epoch 182/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 55.7143\n",
      "Epoch 183/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 57.8282\n",
      "Epoch 184/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 56.4235\n",
      "Epoch 185/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 54.2564\n",
      "Epoch 186/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 54.9141\n",
      "Epoch 187/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 57.7593\n",
      "Epoch 188/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 61.0172\n",
      "Epoch 189/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 57.4604\n",
      "Epoch 190/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 56.2275\n",
      "Epoch 191/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 64.3533\n",
      "Epoch 192/282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 6s 23ms/step - loss: 55.5200\n",
      "Epoch 193/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 54.1491\n",
      "Epoch 194/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 55.9494\n",
      "Epoch 195/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 54.0143\n",
      "Epoch 196/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 54.5349\n",
      "Epoch 197/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 57.9223\n",
      "Epoch 198/282\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 55.8227\n",
      "Epoch 199/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 58.7054\n",
      "Epoch 200/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 55.4508\n",
      "Epoch 201/282\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 56.3625\n",
      "Epoch 202/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 52.2014\n",
      "Epoch 203/282\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 53.9830\n",
      "Epoch 204/282\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 54.0352\n",
      "Epoch 205/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 57.7395\n",
      "Epoch 206/282\n",
      "243/243 [==============================] - 5s 23ms/step - loss: 57.1672\n",
      "Epoch 207/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 55.4952\n",
      "Epoch 208/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 59.0631\n",
      "Epoch 209/282\n",
      "243/243 [==============================] - 5s 23ms/step - loss: 51.2228\n",
      "Epoch 210/282\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 53.6803\n",
      "Epoch 211/282\n",
      "243/243 [==============================] - 6s 23ms/step - loss: 57.6578\n",
      "Epoch 212/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 55.3121\n",
      "Epoch 213/282\n",
      "243/243 [==============================] - 5s 22ms/step - loss: 54.7949\n",
      "Epoch 214/282\n",
      "243/243 [==============================] - 4s 15ms/step - loss: 55.0070\n",
      "Epoch 215/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 59.1847\n",
      "Epoch 216/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 53.5587\n",
      "Epoch 217/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 51.2585\n",
      "Epoch 218/282\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 56.4431\n",
      "Epoch 219/282\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 54.1311\n",
      "Epoch 220/282\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 56.0137\n",
      "Epoch 221/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 54.9968\n",
      "Epoch 222/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 58.6083\n",
      "Epoch 223/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 53.1474\n",
      "Epoch 224/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 54.0588\n",
      "Epoch 225/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 58.4146\n",
      "Epoch 226/282\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 52.8394\n",
      "Epoch 227/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 57.8310\n",
      "Epoch 228/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 53.2924\n",
      "Epoch 229/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 57.1871\n",
      "Epoch 230/282\n",
      "243/243 [==============================] - 4s 15ms/step - loss: 55.1804\n",
      "Epoch 231/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 55.1360\n",
      "Epoch 232/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 52.7391\n",
      "Epoch 233/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 55.1862\n",
      "Epoch 234/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 53.5656\n",
      "Epoch 235/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 55.8054\n",
      "Epoch 236/282\n",
      "243/243 [==============================] - 8s 31ms/step - loss: 53.9904\n",
      "Epoch 237/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 53.6969\n",
      "Epoch 238/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 52.7723\n",
      "Epoch 239/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 53.9682\n",
      "Epoch 240/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 52.8312\n",
      "Epoch 241/282\n",
      "243/243 [==============================] - 7s 31ms/step - loss: 50.7844\n",
      "Epoch 242/282\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 48.7640 0s -\n",
      "Epoch 243/282\n",
      "243/243 [==============================] - 8s 31ms/step - loss: 50.4241\n",
      "Epoch 244/282\n",
      "243/243 [==============================] - 7s 31ms/step - loss: 52.1322\n",
      "Epoch 245/282\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 59.9708\n",
      "Epoch 246/282\n",
      "243/243 [==============================] - 4s 15ms/step - loss: 50.9688\n",
      "Epoch 247/282\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 53.3650\n",
      "Epoch 248/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 52.8780\n",
      "Epoch 249/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 50.3071\n",
      "Epoch 250/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 52.1907\n",
      "Epoch 251/282\n",
      "243/243 [==============================] - 5s 20ms/step - loss: 52.3997\n",
      "Epoch 252/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 54.2730\n",
      "Epoch 253/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 51.0154\n",
      "Epoch 254/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 53.8791\n",
      "Epoch 255/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 53.3842\n",
      "Epoch 256/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 52.2537\n",
      "Epoch 257/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 48.5674\n",
      "Epoch 258/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 48.5518\n",
      "Epoch 259/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 54.5551\n",
      "Epoch 260/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 49.7757\n",
      "Epoch 261/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 47.9887\n",
      "Epoch 262/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 48.9957\n",
      "Epoch 263/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 52.8456\n",
      "Epoch 264/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 49.3796\n",
      "Epoch 265/282\n",
      "243/243 [==============================] - 4s 18ms/step - loss: 51.7208\n",
      "Epoch 266/282\n",
      "243/243 [==============================] - 5s 19ms/step - loss: 56.6364\n",
      "Epoch 267/282\n",
      "243/243 [==============================] - 4s 15ms/step - loss: 48.6506\n",
      "Epoch 268/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 51.4206\n",
      "Epoch 269/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 47.9733\n",
      "Epoch 270/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 51.5000\n",
      "Epoch 271/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 51.0058\n",
      "Epoch 272/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 49.8540\n",
      "Epoch 273/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 48.0225\n",
      "Epoch 274/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 47.8484\n",
      "Epoch 275/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 48.2741\n",
      "Epoch 276/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 46.0166\n",
      "Epoch 277/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 48.3574\n",
      "Epoch 278/282\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 49.4747\n",
      "Epoch 279/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 49.2026\n",
      "Epoch 280/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 48.8231\n",
      "Epoch 281/282\n",
      "243/243 [==============================] - 6s 25ms/step - loss: 51.3247\n",
      "Epoch 282/282\n",
      "243/243 [==============================] - 6s 24ms/step - loss: 48.1648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f47c41012e0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y)\n",
    "plt.plot(yhat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 441.24  Expected: 448.58\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted: {yhat[0][0]:.2f}  Expected: {y_expected[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THIS IS NOT AN INVESTMENT ADVICE!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
