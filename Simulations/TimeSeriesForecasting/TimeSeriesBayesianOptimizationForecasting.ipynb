{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series BayesianOptimization Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "* [Time Series Forecasting on Stock Prices](https://www.youtube.com/watch?v=j05UUs99eNQ) from [Coding Tech](https://www.youtube.com/channel/UCtxCXg-UvSnTKPOzLH4wJaQ)\n",
    "\n",
    "Related:\n",
    "* https://iknowfirst.com/stock-forecast-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** _Investing in the stock market involves risk and can lead to monetary loss. This material is purely for educational purposes and should not be taken as professional investment advice. Invest at your own discretion._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SP500.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>94.484962</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>775500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>92.169162</td>\n",
       "      <td>94.190231</td>\n",
       "      <td>1850600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>373900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-24</td>\n",
       "      <td>92.800753</td>\n",
       "      <td>94.358660</td>\n",
       "      <td>92.063905</td>\n",
       "      <td>94.148132</td>\n",
       "      <td>400300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-25</td>\n",
       "      <td>94.337613</td>\n",
       "      <td>94.948145</td>\n",
       "      <td>92.884970</td>\n",
       "      <td>93.284973</td>\n",
       "      <td>69600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5359</th>\n",
       "      <td>2021-09-08</td>\n",
       "      <td>452.899994</td>\n",
       "      <td>453.679993</td>\n",
       "      <td>450.869995</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>4076800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5360</th>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>452.690002</td>\n",
       "      <td>454.579987</td>\n",
       "      <td>450.730011</td>\n",
       "      <td>450.980011</td>\n",
       "      <td>3851600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5361</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>453.059998</td>\n",
       "      <td>453.510010</td>\n",
       "      <td>447.299988</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>3023500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>450.679993</td>\n",
       "      <td>450.929993</td>\n",
       "      <td>446.089996</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>3007400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>450.079987</td>\n",
       "      <td>450.320007</td>\n",
       "      <td>445.200012</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>3658400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5364 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Volume  \\\n",
       "0     2000-05-19   96.106028   96.106028   94.484962   94.779701   775500   \n",
       "1     2000-05-22   94.716551   94.716551   92.169162   94.190231  1850600   \n",
       "2     2000-05-23   94.463952   94.463952   92.758675   92.758675   373900   \n",
       "3     2000-05-24   92.800753   94.358660   92.063905   94.148132   400300   \n",
       "4     2000-05-25   94.337613   94.948145   92.884970   93.284973    69600   \n",
       "...          ...         ...         ...         ...         ...      ...   \n",
       "5359  2021-09-08  452.899994  453.679993  450.869995  453.000000  4076800   \n",
       "5360  2021-09-09  452.690002  454.579987  450.730011  450.980011  3851600   \n",
       "5361  2021-09-10  453.059998  453.510010  447.299988  447.540009  3023500   \n",
       "5362  2021-09-13  450.679993  450.929993  446.089996  448.579987  3007400   \n",
       "5363  2021-09-14  450.079987  450.320007  445.200012  446.190002  3658400   \n",
       "\n",
       "      Dividends  Stock Splits  \n",
       "0           0.0             0  \n",
       "1           0.0             0  \n",
       "2           0.0             0  \n",
       "3           0.0             0  \n",
       "4           0.0             0  \n",
       "...         ...           ...  \n",
       "5359        0.0             0  \n",
       "5360        0.0             0  \n",
       "5361        0.0             0  \n",
       "5362        0.0             0  \n",
       "5363        0.0             0  \n",
       "\n",
       "[5364 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add indices for every day in the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = df.Date.min()\n",
    "end_date = df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = pd.date_range(start=start_date, end=end_date).to_frame(name=\"Date\")\n",
    "df_date.reset_index(drop=True, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.merge(df_date, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.interpolate(method='linear', limit_direction='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>96.106028</td>\n",
       "      <td>94.484962</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>7.755000e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-20</td>\n",
       "      <td>95.642869</td>\n",
       "      <td>95.642869</td>\n",
       "      <td>93.713029</td>\n",
       "      <td>94.583211</td>\n",
       "      <td>1.133867e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-21</td>\n",
       "      <td>95.179710</td>\n",
       "      <td>95.179710</td>\n",
       "      <td>92.941096</td>\n",
       "      <td>94.386721</td>\n",
       "      <td>1.492233e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>94.716551</td>\n",
       "      <td>92.169162</td>\n",
       "      <td>94.190231</td>\n",
       "      <td>1.850600e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>94.463952</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>3.739000e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>453.059998</td>\n",
       "      <td>453.510010</td>\n",
       "      <td>447.299988</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>3.023500e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>452.266663</td>\n",
       "      <td>452.650004</td>\n",
       "      <td>446.896657</td>\n",
       "      <td>447.886668</td>\n",
       "      <td>3.018133e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>451.473328</td>\n",
       "      <td>451.789998</td>\n",
       "      <td>446.493327</td>\n",
       "      <td>448.233327</td>\n",
       "      <td>3.012767e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>450.679993</td>\n",
       "      <td>450.929993</td>\n",
       "      <td>446.089996</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>3.007400e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>450.079987</td>\n",
       "      <td>450.320007</td>\n",
       "      <td>445.200012</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>3.658400e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7789 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close        Volume  \\\n",
       "0    2000-05-19   96.106028   96.106028   94.484962   94.779701  7.755000e+05   \n",
       "1    2000-05-20   95.642869   95.642869   93.713029   94.583211  1.133867e+06   \n",
       "2    2000-05-21   95.179710   95.179710   92.941096   94.386721  1.492233e+06   \n",
       "3    2000-05-22   94.716551   94.716551   92.169162   94.190231  1.850600e+06   \n",
       "4    2000-05-23   94.463952   94.463952   92.758675   92.758675  3.739000e+05   \n",
       "...         ...         ...         ...         ...         ...           ...   \n",
       "7784 2021-09-10  453.059998  453.510010  447.299988  447.540009  3.023500e+06   \n",
       "7785 2021-09-11  452.266663  452.650004  446.896657  447.886668  3.018133e+06   \n",
       "7786 2021-09-12  451.473328  451.789998  446.493327  448.233327  3.012767e+06   \n",
       "7787 2021-09-13  450.679993  450.929993  446.089996  448.579987  3.007400e+06   \n",
       "7788 2021-09-14  450.079987  450.320007  445.200012  446.190002  3.658400e+06   \n",
       "\n",
       "      Dividends  Stock Splits  \n",
       "0           0.0           0.0  \n",
       "1           0.0           0.0  \n",
       "2           0.0           0.0  \n",
       "3           0.0           0.0  \n",
       "4           0.0           0.0  \n",
       "...         ...           ...  \n",
       "7784        0.0           0.0  \n",
       "7785        0.0           0.0  \n",
       "7786        0.0           0.0  \n",
       "7787        0.0           0.0  \n",
       "7788        0.0           0.0  \n",
       "\n",
       "[7789 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove not needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Date', 'Close']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>94.779701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-20</td>\n",
       "      <td>94.583211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-21</td>\n",
       "      <td>94.386721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.190231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>92.758675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>447.540009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>447.886668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>448.233327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>448.579987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>446.190002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7789 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close\n",
       "0    2000-05-19   94.779701\n",
       "1    2000-05-20   94.583211\n",
       "2    2000-05-21   94.386721\n",
       "3    2000-05-22   94.190231\n",
       "4    2000-05-23   92.758675\n",
       "...         ...         ...\n",
       "7784 2021-09-10  447.540009\n",
       "7785 2021-09-11  447.886668\n",
       "7786 2021-09-12  448.233327\n",
       "7787 2021-09-13  448.579987\n",
       "7788 2021-09-14  446.190002\n",
       "\n",
       "[7789 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple Moving Average**\n",
    "* Example periods: 15, 30 or 45 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSMA(data, period, column='Close'):\n",
    "    return data[column].rolling(window=period).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SMA'] = computeSMA(df, period=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exponential Moving Averages**\n",
    "* Example periods: 15, 30 or 45 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEMA(data, period, column='Close'):\n",
    "    return data[column].ewm(span=period, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EMA'] = computeEMA(df, period=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relative Strength Index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRSI(data, period=14, column='Close'):\n",
    "    delta = data[column].diff(1)\n",
    "    delta = delta.dropna()\n",
    "    up = delta.copy()\n",
    "    down = delta.copy()\n",
    "    up[up < 0] = 0\n",
    "    down[down > 0] = 0\n",
    "    data['up'] = up\n",
    "    data['down'] = down\n",
    "    AVG_Gain = computeSMA(data, period, column='up')\n",
    "    AVG_Loss = abs(computeSMA(data, period, column='down'))\n",
    "    RS = AVG_Gain / AVG_Loss\n",
    "    RSI = 100.0 - (100.0 / (1.0 + RS))\n",
    "    return RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RSI'] = computeRSI(df, period=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Moving Average Convergence Divergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD(data, period1=26, period2=12, signal=9, column='Close'):\n",
    "    exp1 = computeEMA(data,period1, column=column)\n",
    "    exp2 = computeEMA(data,period2, column=column)\n",
    "    data['MACD'] = exp2 - exp1\n",
    "    data['Signal Line'] = computeSMA(data, signal, column='MACD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACD(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>SMA</th>\n",
       "      <th>EMA</th>\n",
       "      <th>up</th>\n",
       "      <th>down</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.779701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-20</td>\n",
       "      <td>94.583211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.755140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-21</td>\n",
       "      <td>94.386721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.709088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.043451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-22</td>\n",
       "      <td>94.190231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.644231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.080392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-23</td>\n",
       "      <td>92.758675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.408536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.431557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.222617</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>453.257671</td>\n",
       "      <td>451.878931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.440002</td>\n",
       "      <td>30.279938</td>\n",
       "      <td>1.487905</td>\n",
       "      <td>2.619024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>447.886668</td>\n",
       "      <td>452.970782</td>\n",
       "      <td>451.379898</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.313930</td>\n",
       "      <td>1.046934</td>\n",
       "      <td>2.394046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>448.233327</td>\n",
       "      <td>452.662337</td>\n",
       "      <td>450.986577</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.233827</td>\n",
       "      <td>0.717167</td>\n",
       "      <td>2.129901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>452.332335</td>\n",
       "      <td>450.685753</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.029401</td>\n",
       "      <td>0.478284</td>\n",
       "      <td>1.844411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>451.798335</td>\n",
       "      <td>450.123784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.389984</td>\n",
       "      <td>20.440156</td>\n",
       "      <td>0.095020</td>\n",
       "      <td>1.527523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7789 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close         SMA         EMA        up      down  \\\n",
       "0    2000-05-19   94.779701         NaN   94.779701       NaN       NaN   \n",
       "1    2000-05-20   94.583211         NaN   94.755140  0.000000 -0.196490   \n",
       "2    2000-05-21   94.386721         NaN   94.709088  0.000000 -0.196490   \n",
       "3    2000-05-22   94.190231         NaN   94.644231  0.000000 -0.196490   \n",
       "4    2000-05-23   92.758675         NaN   94.408536  0.000000 -1.431557   \n",
       "...         ...         ...         ...         ...       ...       ...   \n",
       "7784 2021-09-10  447.540009  453.257671  451.878931  0.000000 -3.440002   \n",
       "7785 2021-09-11  447.886668  452.970782  451.379898  0.346659  0.000000   \n",
       "7786 2021-09-12  448.233327  452.662337  450.986577  0.346659  0.000000   \n",
       "7787 2021-09-13  448.579987  452.332335  450.685753  0.346659  0.000000   \n",
       "7788 2021-09-14  446.190002  451.798335  450.123784  0.000000 -2.389984   \n",
       "\n",
       "            RSI      MACD  Signal Line  \n",
       "0           NaN  0.000000          NaN  \n",
       "1           NaN -0.015674          NaN  \n",
       "2           NaN -0.043451          NaN  \n",
       "3           NaN -0.080392          NaN  \n",
       "4           NaN -0.222617          NaN  \n",
       "...         ...       ...          ...  \n",
       "7784  30.279938  1.487905     2.619024  \n",
       "7785  28.313930  1.046934     2.394046  \n",
       "7786  26.233827  0.717167     2.129901  \n",
       "7787  24.029401  0.478284     1.844411  \n",
       "7788  20.440156  0.095020     1.527523  \n",
       "\n",
       "[7789 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>SMA</th>\n",
       "      <th>EMA</th>\n",
       "      <th>up</th>\n",
       "      <th>down</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2000-06-02</td>\n",
       "      <td>99.663971</td>\n",
       "      <td>94.910938</td>\n",
       "      <td>95.600925</td>\n",
       "      <td>1.936874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.245582</td>\n",
       "      <td>0.680463</td>\n",
       "      <td>-0.042866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2000-06-03</td>\n",
       "      <td>99.446431</td>\n",
       "      <td>95.222053</td>\n",
       "      <td>96.081613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217539</td>\n",
       "      <td>71.115354</td>\n",
       "      <td>0.916439</td>\n",
       "      <td>0.090681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2000-06-04</td>\n",
       "      <td>99.228892</td>\n",
       "      <td>95.531765</td>\n",
       "      <td>96.475023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217539</td>\n",
       "      <td>70.985601</td>\n",
       "      <td>1.073524</td>\n",
       "      <td>0.250695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2000-06-05</td>\n",
       "      <td>99.011353</td>\n",
       "      <td>95.840074</td>\n",
       "      <td>96.792064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217539</td>\n",
       "      <td>70.856321</td>\n",
       "      <td>1.167008</td>\n",
       "      <td>0.420929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2000-06-06</td>\n",
       "      <td>98.506065</td>\n",
       "      <td>96.127796</td>\n",
       "      <td>97.006314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.505287</td>\n",
       "      <td>77.029581</td>\n",
       "      <td>1.186644</td>\n",
       "      <td>0.585988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>447.540009</td>\n",
       "      <td>453.257671</td>\n",
       "      <td>451.878931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.440002</td>\n",
       "      <td>30.279938</td>\n",
       "      <td>1.487905</td>\n",
       "      <td>2.619024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>447.886668</td>\n",
       "      <td>452.970782</td>\n",
       "      <td>451.379898</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.313930</td>\n",
       "      <td>1.046934</td>\n",
       "      <td>2.394046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>448.233327</td>\n",
       "      <td>452.662337</td>\n",
       "      <td>450.986577</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.233827</td>\n",
       "      <td>0.717167</td>\n",
       "      <td>2.129901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>448.579987</td>\n",
       "      <td>452.332335</td>\n",
       "      <td>450.685753</td>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.029401</td>\n",
       "      <td>0.478284</td>\n",
       "      <td>1.844411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>446.190002</td>\n",
       "      <td>451.798335</td>\n",
       "      <td>450.123784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.389984</td>\n",
       "      <td>20.440156</td>\n",
       "      <td>0.095020</td>\n",
       "      <td>1.527523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7775 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close         SMA         EMA        up      down  \\\n",
       "14   2000-06-02   99.663971   94.910938   95.600925  1.936874  0.000000   \n",
       "15   2000-06-03   99.446431   95.222053   96.081613  0.000000 -0.217539   \n",
       "16   2000-06-04   99.228892   95.531765   96.475023  0.000000 -0.217539   \n",
       "17   2000-06-05   99.011353   95.840074   96.792064  0.000000 -0.217539   \n",
       "18   2000-06-06   98.506065   96.127796   97.006314  0.000000 -0.505287   \n",
       "...         ...         ...         ...         ...       ...       ...   \n",
       "7784 2021-09-10  447.540009  453.257671  451.878931  0.000000 -3.440002   \n",
       "7785 2021-09-11  447.886668  452.970782  451.379898  0.346659  0.000000   \n",
       "7786 2021-09-12  448.233327  452.662337  450.986577  0.346659  0.000000   \n",
       "7787 2021-09-13  448.579987  452.332335  450.685753  0.346659  0.000000   \n",
       "7788 2021-09-14  446.190002  451.798335  450.123784  0.000000 -2.389984   \n",
       "\n",
       "            RSI      MACD  Signal Line  \n",
       "14    71.245582  0.680463    -0.042866  \n",
       "15    71.115354  0.916439     0.090681  \n",
       "16    70.985601  1.073524     0.250695  \n",
       "17    70.856321  1.167008     0.420929  \n",
       "18    77.029581  1.186644     0.585988  \n",
       "...         ...       ...          ...  \n",
       "7784  30.279938  1.487905     2.619024  \n",
       "7785  28.313930  1.046934     2.394046  \n",
       "7786  26.233827  0.717167     2.129901  \n",
       "7787  24.029401  0.478284     1.844411  \n",
       "7788  20.440156  0.095020     1.527523  \n",
       "\n",
       "[7775 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq1 = df['SMA'].values\n",
    "in_seq2 = df['EMA'].values\n",
    "in_seq3 = df['RSI'].values\n",
    "in_seq4 = df['MACD'].values\n",
    "in_seq5 = df['Signal Line'].values\n",
    "out_seq = df['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "in_seq3 = in_seq3.reshape((len(in_seq3), 1))\n",
    "in_seq4 = in_seq4.reshape((len(in_seq4), 1))\n",
    "in_seq5 = in_seq5.reshape((len(in_seq5), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.hstack((in_seq1, in_seq2, in_seq3, in_seq4, in_seq5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset)\n",
    "dataset = scaler.transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimensionality reduction - PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca = pca.transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive feature elimination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVR(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = RFE(estimator, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/vladiant/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(dataset_pca, out_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: [ True  True False False False]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Selected features: {selector.support_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features ranking: [1 1 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features ranking: {selector.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9993543829868292\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score: {selector.score(dataset_pca, out_seq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = selector.transform(dataset_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.hstack((dataset, out_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a number of time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate a multivariate sequence into samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # Find the end of the pattern\n",
    "        end_ix = i + n_steps\n",
    "        # Check if we are bound by sequence\n",
    "        if end_ix > len(sequences) - 1:\n",
    "            break\n",
    "        # Gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert into input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequences(dataset, n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset knows the number of the features, e.g. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = n_steps\n",
    "prediction_size = n_features\n",
    "y_test = y[-test_size-prediction_size:-prediction_size]\n",
    "X_test = X[-test_size-prediction_size:-prediction_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_expected = y[-prediction_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[:-test_size-prediction_size]\n",
    "X = X[:-test_size-prediction_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define model**\n",
    "\n",
    "Keras Random Search - optimize: LSTM units, Dropout Rate, Learning Rate, Sequence Length\n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-with-keras-tuner-283474fbfbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    hp_units_1 = hp.Int('units_1', min_value=10, max_value=250, step=10)\n",
    "    model.add(LSTM(hp_units_1, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    \n",
    "    dropout_rate_1 = hp.Float('dropout_1', 0, 0.9, step=0.1, default=0.5)\n",
    "    model.add(Dropout(dropout_rate_1))\n",
    "    \n",
    "    hp_units_2 = hp.Int('units_2', min_value=10, max_value=250, step=10)\n",
    "    model.add(LSTM(hp_units_2, activation='relu'))\n",
    "    \n",
    "    dropout_rate_2 = hp.Float('dropout_2', 0, 0.9, step=0.1, default=0.5)\n",
    "    model.add(Dropout(dropout_rate_2))\n",
    "    \n",
    "    model.add(Dense(n_features))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ts_test_dir/ts_forecast_bayes_tune/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ts_test_dir/ts_forecast_bayes_tune/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.BayesianOptimization(model_builder,\n",
    "                                objective='loss',\n",
    "                                max_trials=100,\n",
    "                                executions_per_trial=2,\n",
    "                                directory='ts_test_dir',\n",
    "                                project_name='ts_forecast_bayes_tune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 04m 23s]\n",
      "loss: 306.4560241699219\n",
      "\n",
      "Best loss So Far: 15.603438377380371\n",
      "Total elapsed time: 01h 51m 40s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X, y, epochs=100, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of LSTM units are 10 and 10 \n",
      "The dropouts are 0.0 and 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The optimal number of LSTM units are {best_hps.get('units_1')} and {best_hps.get('units_2')} \")\n",
    "print(f\"The dropouts are {best_hps.get('dropout_1')} and {best_hps.get('dropout_2')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with the optimal hyperparameters and train it on the data for 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13486.7598\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 66.8239\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 24.9296\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 20.9870\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.6266\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 18.0374\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.1948\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 17.1833\n",
      "Epoch 9/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 17.3505\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.3708\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16.5857\n",
      "Epoch 12/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.5502\n",
      "Epoch 13/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 17.1372\n",
      "Epoch 14/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16.1940\n",
      "Epoch 15/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.2111\n",
      "Epoch 16/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.4085\n",
      "Epoch 17/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16.8753\n",
      "Epoch 18/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.9797\n",
      "Epoch 19/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.8895\n",
      "Epoch 20/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16.8541\n",
      "Epoch 21/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16.3599\n",
      "Epoch 22/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.4269\n",
      "Epoch 23/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.5728\n",
      "Epoch 24/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 17.6170\n",
      "Epoch 25/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.8764\n",
      "Epoch 26/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.0930\n",
      "Epoch 27/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.2157\n",
      "Epoch 28/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.3801\n",
      "Epoch 29/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 17.0711\n",
      "Epoch 30/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.4994\n",
      "Epoch 31/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.2650\n",
      "Epoch 32/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.2943\n",
      "Epoch 33/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.5677\n",
      "Epoch 34/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.1559\n",
      "Epoch 35/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.6845\n",
      "Epoch 36/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.7075\n",
      "Epoch 37/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.6328\n",
      "Epoch 38/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.0184\n",
      "Epoch 39/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 13.6966\n",
      "Epoch 40/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.2441\n",
      "Epoch 41/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.7166\n",
      "Epoch 42/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.7191\n",
      "Epoch 43/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.6396\n",
      "Epoch 44/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.2407\n",
      "Epoch 45/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.9220\n",
      "Epoch 46/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.4869\n",
      "Epoch 47/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.5648\n",
      "Epoch 48/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.7777\n",
      "Epoch 49/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.5435\n",
      "Epoch 50/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.4286\n",
      "Epoch 51/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.2987\n",
      "Epoch 52/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 13.7096\n",
      "Epoch 53/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.4663\n",
      "Epoch 54/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.0229\n",
      "Epoch 55/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.8860\n",
      "Epoch 56/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.7654\n",
      "Epoch 57/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.7214\n",
      "Epoch 58/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.4335\n",
      "Epoch 59/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.1651\n",
      "Epoch 60/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.3514\n",
      "Epoch 61/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12.5165\n",
      "Epoch 62/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.2763\n",
      "Epoch 63/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.8002\n",
      "Epoch 64/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.0135\n",
      "Epoch 65/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.2684\n",
      "Epoch 66/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 13.8547\n",
      "Epoch 67/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 12.2616\n",
      "Epoch 68/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.0466\n",
      "Epoch 69/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 13.5429\n",
      "Epoch 70/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.6362\n",
      "Epoch 71/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 13.4682\n",
      "Epoch 72/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.6743\n",
      "Epoch 73/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.0742\n",
      "Epoch 74/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 13.0500\n",
      "Epoch 75/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.0919\n",
      "Epoch 76/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 13.5231\n",
      "Epoch 77/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 13.2824\n",
      "Epoch 78/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12.8697\n",
      "Epoch 79/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 12.5265\n",
      "Epoch 80/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 12.6781\n",
      "Epoch 81/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 12.4390\n",
      "Epoch 82/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12.8077\n",
      "Epoch 83/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12.2279\n",
      "Epoch 84/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 13.6066\n",
      "Epoch 85/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12.4613\n",
      "Epoch 86/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12.7251\n",
      "Epoch 87/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 12.7583\n",
      "Epoch 88/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.9101\n",
      "Epoch 89/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.2056\n",
      "Epoch 90/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 12.0881\n",
      "Epoch 91/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 12.3363\n",
      "Epoch 92/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 12.5357\n",
      "Epoch 93/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12.9370\n",
      "Epoch 94/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12.8514\n",
      "Epoch 95/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12.0558\n",
      "Epoch 96/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 12.0389\n",
      "Epoch 97/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 11.7818\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 1s 4ms/step - loss: 12.3427\n",
      "Epoch 99/100\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12.3800\n",
      "Epoch 100/100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 12.1050\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 97\n"
     ]
    }
   ],
   "source": [
    "loss_per_epoch = history.history['loss']\n",
    "best_epoch = loss_per_epoch.index(min(loss_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12264.4502\n",
      "Epoch 2/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 198.4885\n",
      "Epoch 3/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 88.6811\n",
      "Epoch 4/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 44.2495\n",
      "Epoch 5/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 29.6846\n",
      "Epoch 6/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 24.8920\n",
      "Epoch 7/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 22.8828\n",
      "Epoch 8/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 20.7842\n",
      "Epoch 9/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 21.4818\n",
      "Epoch 10/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 21.0137\n",
      "Epoch 11/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 20.8144\n",
      "Epoch 12/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 20.5308\n",
      "Epoch 13/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 18.9440\n",
      "Epoch 14/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 20.1668\n",
      "Epoch 15/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 18.9754\n",
      "Epoch 16/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 20.9005\n",
      "Epoch 17/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.9558\n",
      "Epoch 18/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.9590\n",
      "Epoch 19/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.6015\n",
      "Epoch 20/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.0860\n",
      "Epoch 21/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.2337\n",
      "Epoch 22/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.8151\n",
      "Epoch 23/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 22.7257\n",
      "Epoch 24/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.3705\n",
      "Epoch 25/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.3142\n",
      "Epoch 26/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.4564\n",
      "Epoch 27/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.9943\n",
      "Epoch 28/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.0781\n",
      "Epoch 29/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.1075\n",
      "Epoch 30/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.9569\n",
      "Epoch 31/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.0857\n",
      "Epoch 32/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.5714\n",
      "Epoch 33/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.4007\n",
      "Epoch 34/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.5634\n",
      "Epoch 35/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 17.4769\n",
      "Epoch 36/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.1720\n",
      "Epoch 37/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.3483\n",
      "Epoch 38/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.2218\n",
      "Epoch 39/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.0133\n",
      "Epoch 40/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 17.8029\n",
      "Epoch 41/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 17.2238\n",
      "Epoch 42/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.3701\n",
      "Epoch 43/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.6131\n",
      "Epoch 44/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.4403\n",
      "Epoch 45/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.9348\n",
      "Epoch 46/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.0147\n",
      "Epoch 47/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 19.9656\n",
      "Epoch 48/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 17.4908\n",
      "Epoch 49/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 17.1896\n",
      "Epoch 50/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 19.6604\n",
      "Epoch 51/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 17.4278\n",
      "Epoch 52/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 17.6547\n",
      "Epoch 53/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.0209\n",
      "Epoch 54/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.8846\n",
      "Epoch 55/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16.7112\n",
      "Epoch 56/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.1557\n",
      "Epoch 57/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16.9366\n",
      "Epoch 58/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.9873\n",
      "Epoch 59/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.1355\n",
      "Epoch 60/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 17.6209\n",
      "Epoch 61/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.8078\n",
      "Epoch 62/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.6441\n",
      "Epoch 63/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 17.6825\n",
      "Epoch 64/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.6204\n",
      "Epoch 65/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16.4527\n",
      "Epoch 66/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16.3707\n",
      "Epoch 67/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.0716\n",
      "Epoch 68/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.5057\n",
      "Epoch 69/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 18.8303\n",
      "Epoch 70/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.5167\n",
      "Epoch 71/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.9680\n",
      "Epoch 72/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.0785\n",
      "Epoch 73/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.9418\n",
      "Epoch 74/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.4304\n",
      "Epoch 75/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.6708\n",
      "Epoch 76/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16.9756\n",
      "Epoch 77/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 16.3314\n",
      "Epoch 78/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.7506\n",
      "Epoch 79/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.4390\n",
      "Epoch 80/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16.6280\n",
      "Epoch 81/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.4719\n",
      "Epoch 82/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.0218\n",
      "Epoch 83/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.8640\n",
      "Epoch 84/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.4662\n",
      "Epoch 85/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13.9243\n",
      "Epoch 86/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.2584\n",
      "Epoch 87/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.8052\n",
      "Epoch 88/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.7633\n",
      "Epoch 89/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.2035\n",
      "Epoch 90/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 13.8713\n",
      "Epoch 91/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.8353\n",
      "Epoch 92/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 14.4196\n",
      "Epoch 93/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.1618\n",
      "Epoch 94/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15.2746\n",
      "Epoch 95/97\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14.3359\n",
      "Epoch 96/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 15.3351\n",
      "Epoch 97/97\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 17.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd07067da30>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y)\n",
    "plt.plot(yhat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 463.71  Expected: 448.58\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted: {yhat[0][0]:.2f}  Expected: {y_expected[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THIS IS NOT AN INVESTMENT ADVICE!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
